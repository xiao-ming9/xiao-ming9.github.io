<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Mist',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":true},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="1. Redis数据类型Redis提供了String,Hash,List,Set,Zset五种数据类型。 StringString数据结构是最简单的key-value类型，value不仅可以是String,也可以是数字，包括整数，浮点数和二进制数。 主要的应用有：缓存，计数，共享session和限速">
<meta name="keywords" content="Redis,面试">
<meta property="og:type" content="article">
<meta property="og:title" content="数据库Redis">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;10&#x2F;11&#x2F;%E9%9D%A2%E8%AF%95%E5%A4%8D%E4%B9%A0%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%BA%93Redis&#x2F;index.html">
<meta property="og:site_name" content="Silverming">
<meta property="og:description" content="1. Redis数据类型Redis提供了String,Hash,List,Set,Zset五种数据类型。 StringString数据结构是最简单的key-value类型，value不仅可以是String,也可以是数字，包括整数，浮点数和二进制数。 主要的应用有：缓存，计数，共享session和限速">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http:&#x2F;&#x2F;qiniu.xiaoming.net.cn&#x2F;Redis%E4%B8%80%E6%AC%A1%E9%80%9A%E8%A1%8C%E8%BF%87%E7%A8%8B.webp">
<meta property="og:image" content="http:&#x2F;&#x2F;qiniu.xiaoming.net.cn&#x2F;%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.jpeg">
<meta property="og:image" content="https:&#x2F;&#x2F;camo.githubusercontent.com&#x2F;b1fd3e057266f0ca21f69e2a26f420f9564c5cdb&#x2F;68747470733a2f2f6d617274696e2e6b6c6570706d616e6e2e636f6d2f323031362f30322f756e736166652d6c6f636b2e706e67">
<meta property="og:image" content="https:&#x2F;&#x2F;camo.githubusercontent.com&#x2F;4ca3c6919e560b60b130c4f856d2736314713e62&#x2F;68747470733a2f2f6d617274696e2e6b6c6570706d616e6e2e636f6d2f323031362f30322f66656e63696e672d746f6b656e732e706e67">
<meta property="og:image" content="http:&#x2F;&#x2F;qiniu.xiaoming.net.cn&#x2F;ziplist%E7%BB%93%E6%9E%84%E5%9B%BE.png">
<meta property="og:image" content="http:&#x2F;&#x2F;qiniu.xiaoming.net.cn&#x2F;ZSet%E4%B8%ADskiplist%E7%BB%93%E6%9E%84.png">
<meta property="og:image" content="https:&#x2F;&#x2F;camo.githubusercontent.com&#x2F;11e7cbe718a70a81c42c37a13a257f91ef48dfd7&#x2F;687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d31322d392f39333636363231372e6a7067">
<meta property="og:image" content="http:&#x2F;&#x2F;qiniu.xiaoming.net.cn&#x2F;%E8%B7%B3%E8%A1%A8%E7%BB%93%E6%9E%842.png">
<meta property="og:image" content="https:&#x2F;&#x2F;github.com&#x2F;xiao-ming9&#x2F;xiao-ming9.github.io&#x2F;blob&#x2F;master&#x2F;images&#x2F;redis%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA.png?raw=true">
<meta property="og:image" content="https:&#x2F;&#x2F;github.com&#x2F;xiao-ming9&#x2F;xiao-ming9.github.io&#x2F;blob&#x2F;master&#x2F;images&#x2F;redis%E9%9B%86%E7%BE%A4%E5%86%85%E8%8A%82%E7%82%B9%E9%80%9A%E4%BF%A1.png?raw=true">
<meta property="og:image" content="https:&#x2F;&#x2F;github.com&#x2F;xiao-ming9&#x2F;xiao-ming9.github.io&#x2F;blob&#x2F;master&#x2F;images&#x2F;redis%E9%80%89%E4%B8%BE%E5%BB%B6%E8%BF%9F%E5%87%BA%E5%8F%91%E6%9C%BA%E5%88%B6.png?raw=true">
<meta property="og:image" content="http:&#x2F;&#x2F;qiniu.xiaoming.net.cn&#x2F;Redis%E9%9B%86%E7%BE%A4%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB.jpg">
<meta property="og:image" content="http:&#x2F;&#x2F;qiniu.xiaoming.net.cn&#x2F;Redis%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9%E5%AE%89%E5%85%A8%E4%B8%8B%E7%BA%BF.jpg">
<meta property="og:updated_time" content="2020-04-04T14:30:20.560Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http:&#x2F;&#x2F;qiniu.xiaoming.net.cn&#x2F;Redis%E4%B8%80%E6%AC%A1%E9%80%9A%E8%A1%8C%E8%BF%87%E7%A8%8B.webp">

<link rel="canonical" href="http://yoursite.com/2019/10/11/%E9%9D%A2%E8%AF%95%E5%A4%8D%E4%B9%A0%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%BA%93Redis/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>数据库Redis | Silverming</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Silverming</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Stay hungry,stay foolish</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/11/%E9%9D%A2%E8%AF%95%E5%A4%8D%E4%B9%A0%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%BA%93Redis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Silverming">
      <meta itemprop="description" content="Wechat:934933088">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Silverming">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          数据库Redis
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-10-11 07:46:27" itemprop="dateCreated datePublished" datetime="2019-10-11T07:46:27+08:00">2019-10-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-04-04 22:30:20" itemprop="dateModified" datetime="2020-04-04T22:30:20+08:00">2020-04-04</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="1-Redis数据类型"><a href="#1-Redis数据类型" class="headerlink" title="1. Redis数据类型"></a>1. Redis数据类型</h1><p>Redis提供了<code>String</code>,<code>Hash</code>,<code>List</code>,<code>Set</code>,<code>Zset</code>五种数据类型。</p>
<h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><p><code>String</code>数据结构是最简单的<code>key-value</code>类型，<code>value</code>不仅可以是<code>String</code>,也可以是数字，包括整数，浮点数和二进制数。</p>
<p>主要的应用有：缓存，计数，共享<code>session</code>和限速</p>
<a id="more"></a>

<p>内部编码主要有：</p>
<ul>
<li><code>int</code>:8个字节的长整型</li>
<li><code>embstr</code>:小于等于39个字节的字符串</li>
<li><code>raw</code>:大于39个字节的字符串</li>
</ul>
<h3 id="各个指令的时间复杂度"><a href="#各个指令的时间复杂度" class="headerlink" title="各个指令的时间复杂度"></a>各个指令的时间复杂度</h3><ul>
<li><strong>SET</strong>：为一个 key 设置 value，可以配合 EX/PX 参数指定 key 的有效期，通过 NX/XX 参数针对 key 是否存在的情况进行区别操作，时间复杂度 <code>O(1)</code></li>
<li><strong>GET</strong>：获取某个 key 对应的 value，时间复杂度 <code>O(1)</code></li>
<li><strong>GETSET</strong>：为一个 key 设置 value，并返回该 key 的原 value，时间复杂度 <code>O(1)</code></li>
<li><strong>MSET</strong>：为多个 key 设置 value，时间复杂度 <code>O(N)</code></li>
<li><strong>MSETNX</strong>：同 MSET，如果指定的 key 中有任意一个已存在，则不进行任何操作，时间复杂度 <code>O(N)</code></li>
<li><strong>MGET</strong>：获取多个 key 对应的 value，时间复杂度 <code>O(N)</code></li>
<li><strong>INCR</strong>：将 key 对应的 value 值自增1，并返回自增后的值。只对可以转换为整型的 String 数据起作用。时间复杂度 <code>O(1)</code></li>
<li><strong>INCRBY</strong>：将 key 对应的 value 值自增指定的整型数值，并返回自增后的值。只对可以转换为整型的 String 数据起作用。时间复杂度 <code>O(1)</code></li>
<li><strong>DECR/DECRBY</strong>：同 INCR/INCRBY，自增改为自减。</li>
</ul>
<h2 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h2><p><code>Hash</code>是一个<code>string</code>类型的<code>field</code>和<code>value</code>的映射表，<code>hash</code>特别适合用于存储对象，后续操作的时候，可以直接仅仅修改这个对象某个字段的值。比如可以用<code>hash</code>数据结构来存储用户信息，商品信息等。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">key = JavaUser</span><br><span class="line">value = &#123;</span><br><span class="line">    <span class="string">"id"</span>:<span class="number">1</span>,</span><br><span class="line">    <span class="string">"name"</span>:<span class="string">"xiaoming"</span>,</span><br><span class="line">    <span class="string">"age"</span>: <span class="number">22</span>,</span><br><span class="line">    <span class="string">"location"</span>: <span class="string">"GuangDong,Jieyang"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>主要应用有：将关系型数据库每一行数据存储为一个哈希键</p>
<p>内部编码主要：</p>
<ul>
<li><code>ziplist</code>(<strong>压缩列表</strong>)：当哈希类型元素个数小于<code>hash-max-ziplist-entries</code>配置（默认512个字节），同时所有值小于<code>hash-max-ziplist-value</code>配置（默认64个字节）时，使用<code>ziplist</code>作为内部实现，<code>ziplist</code>使用更加紧凑的结构实现多个元素的连续存储，在节省内存方面更加优秀</li>
<li><code>hashtable</code>(<strong>哈希表</strong>)：当哈希类型无法满足<code>ziplist</code>的条件时，使用<code>hashtable</code>作为内部实现，因为此时<code>ziplist</code>读写效率会下降，而<code>hashtable</code>读写时间复杂度为O(1)</li>
</ul>
<h3 id="各个指令的时间复杂度-1"><a href="#各个指令的时间复杂度-1" class="headerlink" title="各个指令的时间复杂度"></a>各个指令的时间复杂度</h3><p>与 Hash 相关的常用命令：</p>
<ul>
<li><strong>HSET</strong>：将 key 对应的 Hash 中的 field 设置为 value。如果该 Hash 不存在，会自动创建一个。时间复杂度 <code>O(1)</code></li>
<li><strong>HGET</strong>：返回指定 Hash 中 field 字段的值，时间复杂度 <code>O(1)</code></li>
<li><strong>HMSET/HMGET</strong>：同 HSET 和 HGET，可以批量操作同一个 key 下的多个 field，时间复杂度：<code>O(N)</code>，N为一次操作的 field 数量</li>
<li><strong>HSETNX</strong>：同 HSET，但如 field 已经存在，HSETNX 不会进行任何操作，时间复杂度 <code>O(1)</code></li>
<li><strong>HEXISTS</strong>：判断指定Hash中 field 是否存在，存在返回1，不存在返回0，时间复杂度 <code>O(1)</code></li>
<li><strong>HDEL</strong>：删除指定 Hash 中的 field（1个或多个），时间复杂度：<code>O(N)</code>，N 为操作的 field 数量</li>
<li><strong>HINCRBY</strong>：同 INCRBY 命令，对指定 Hash 中的一个 field 进行 INCRBY，时间复杂度 <code>O(1)</code></li>
</ul>
<p>应谨慎使用的Hash相关命令：</p>
<ul>
<li><strong>HGETALL</strong>：返回指定 Hash 中所有的 field-value 对。返回结果为数组，数组中 field 和 value 交替出现。时间复杂度 <code>O(N)</code></li>
<li><strong>HKEYS/HVALS</strong>：返回指定 Hash 中所有的 field/value，时间复杂度 <code>O(N)</code></li>
</ul>
<p>上述三个命令都会对 Hash 进行完整遍历，Hash中的 field 数量与命令的耗时线性相关，对于尺寸不可预知的 Hash，应严格避免使用上面三个命令，而改为使用 HSCAN 命令进行游标式的遍历</p>
<h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><p><code>list</code>就是链表，Redis中<code>list</code>的应用场景非常多，也是Redis最重要的数据结构之一</p>
<p><code>list</code>的实现是一个双向链表，既可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。</p>
<p>另外可以通过<code>lrange</code>，就是从某个元素开始读取多少个元素，可以基于<code>list</code>实现分页查询，基于 redis实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西（一页一页的往下走），性能高。</p>
<p>主要的应用有：栈、队列，消息队列（抢购），文章列表等</p>
<p>内部编码有：</p>
<ul>
<li><code>ziplist</code>(<strong>压缩列表</strong>)：当哈希类型元素个数小于<code>list-max-ziplist-entries</code>配置（默认512），同时所有值小于<code>list-max-ziplist-value</code>配置（默认64）时，使用<code>ziplist</code>作为内部实现，<code>ziplist</code>使用更加紧凑的结构实现多个元素的连续存储，在节省内存方面更加优秀</li>
<li><code>linkedlist</code>(<strong>链表</strong>)：当列表类型无法满足<code>ziplist</code>条件时，使用链表作为内部实现</li>
</ul>
<h3 id="各个指令的时间复杂度-2"><a href="#各个指令的时间复杂度-2" class="headerlink" title="各个指令的时间复杂度"></a>各个指令的时间复杂度</h3><ul>
<li><strong>LPUSH</strong>：向指定 List 的左侧（即头部）插入 1 个或多个元素，返回插入后的 List 长度。时间复杂度 <code>O(N)</code>，N 为插入元素的数量</li>
<li><strong>RPUSH</strong>：同 LPUSH，向指定 List 的右侧（即尾部）插入 1 或多个元素</li>
<li><strong>LPOP</strong>：从指定 List 的左侧（即头部）移除一个元素并返回，时间复杂度 <code>O(1)</code></li>
<li><strong>RPOP</strong>：同 LPOP，从指定 List 的右侧（即尾部）移除 1 个元素并返回</li>
<li><strong>LPUSHX/RPUSHX</strong>：与 LPUSH/RPUSH 类似，区别在于，LPUSHX/RPUSHX 操作的 key 如果不存在，则不会进行任何操作</li>
<li><strong>LLEN</strong>：返回指定 List 的长度，时间复杂度 <code>O(1)</code></li>
<li><strong>LRANGE</strong>：返回指定 List 中指定范围的元素（双端包含，即 <code>LRANGE key 0 10</code> 会返回 11 个元素），时间复杂度 <code>O(N)</code>。应尽可能控制一次获取的元素数量，一次获取过大范围的 List 元素会导致延迟，同时对长度不可预知的 List，避免使用 <code>LRANGE key 0 -1</code> 这样的完整遍历操作。</li>
</ul>
<p>应谨慎使用的List相关命令：</p>
<ul>
<li><strong>LINDEX</strong>：返回指定 List 指定 index 上的元素，如果 index 越界，返回nil。index 数值是回环的，即 -1 代表 List 最后一个位置，-2 代表 List 倒数第二个位置。时间复杂度 <code>O(N)</code></li>
<li><strong>LSET</strong>：将指定 List 指定 index 上的元素设置为 value，如果 index 越界则返回错误，时间复杂度 <code>O(N)</code>，如果操作的是头/尾部的元素，则时间复杂度为 <code>O(1)</code></li>
<li><strong>LINSERT</strong>：向指定 List 中指定元素之前/之后插入一个新元素，并返回操作后的 List 长度。如果指定的元素不存在，返回 -1。如果指定 key 不存在，不会进行任何操作，时间复杂度 <code>O(N)</code></li>
</ul>
<p>由于 Redis 的 List 是链表结构的，上述的三个命令的算法效率较低，需要对 List 进行遍历，命令的耗时无法预估，在 List 长度大的情况下耗时会明显增加，应谨慎使用。</p>
<h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><p>集合（<code>set</code>）可以保存多个字符串元素，但是不允许有重复元素，并且集合中的元素是无序的，一个集合最多可以存储<code>2^32-1</code>个元素，集合可以进行内部的增删改查和多个集合取交集，并集，差集。</p>
<p>主要的应用有：标签，生成随机数（抽奖），社交需求（共同好友，粉丝等等）</p>
<p>内部编码主要有：</p>
<ul>
<li><code>intset</code>(<strong>整数集合</strong>)：当集合中的元素都是整数而且元素个数小于<code>set-max-intset-entries</code>配置（默认512个）时，使用该编码减少内存的使用</li>
<li><code>hashtable</code>(<strong>哈希表</strong>)：其它条件下使用哈希表作为内部实现</li>
</ul>
<h3 id="各个指令的时间复杂度-3"><a href="#各个指令的时间复杂度-3" class="headerlink" title="各个指令的时间复杂度"></a>各个指令的时间复杂度</h3><ul>
<li><strong>SADD</strong>：向指定 Set 中添加 1 个或多个 member，如果指定 Set 不存在，会自动创建一个。时间复杂度 <code>O(N)</code>，N 为添加的 member 个数</li>
<li><strong>SREM</strong>：从指定 Set 中移除 1 个或多个 member，时间复杂度 <code>O(N)</code>，N 为移除的 member 个数</li>
<li><strong>SRANDMEMBER</strong>：从指定 Set 中随机返回 1 个或多个 member，时间复杂度 <code>O(N)</code>，N 为返回的 member 个数</li>
<li><strong>SPOP</strong>：从指定 Set 中随机移除并返回 count 个 member，时间复杂度 <code>O(N)</code>，N 为移除的 member 个数</li>
<li><strong>SCARD</strong>：返回指定 Set 中的 member 个数，时间复杂度 <code>O(1)</code></li>
<li><strong>SISMEMBER</strong>：判断指定的 value 是否存在于指定 Set 中，时间复杂度 <code>O(1)</code></li>
<li><strong>SMOVE</strong>：将指定 member 从一个 Set 移至另一个 Set</li>
</ul>
<p>慎用的Set相关命令：</p>
<ul>
<li><strong>SMEMBERS</strong>：返回指定 Hash 中所有的 member，时间复杂度 <code>O(N)</code></li>
<li><strong>SUNION/SUNIONSTORE</strong>：计算多个 Set 的并集并返回/存储至另一个 Set 中，时间复杂度 <code>O(N)</code>，N 为参与计算的所有集合的总 member 数</li>
<li><strong>SINTER/SINTERSTORE</strong>：计算多个 Set 的交集并返回/存储至另一个 Set 中，时间复杂度 <code>O(N)</code>，N 为参与计算的所有集合的总 member 数</li>
<li><strong>SDIFF/SDIFFSTORE</strong>：计算 1 个 Set 与 1 或多个 Set 的差集并返回/存储至另一个 Set 中，时间复杂度 <code>O(N)</code>，N 为参与计算的所有集合的总 member 数</li>
</ul>
<p>上述几个命令涉及的计算量大，应谨慎使用，特别是在参与计算的 Set 尺寸不可知的情况下，应严格避免使用。可以考虑通过 SSCAN 命令遍历获取相关 Set 的全部 member，如果需要做并集/交集/差集计算，可以在客户端进行，或在不服务实时查询请求的 Slave 上进行</p>
<h2 id="ZSet"><a href="#ZSet" class="headerlink" title="ZSet"></a>ZSet</h2><p>有序集合（<code>zset</code>）保留集合元素不能重复的特性，但是有序集合中的元素可以排序，它为每一个元素设定一个score作为排序的依据</p>
<p>应用：排行榜系统，用户点赞</p>
<p>内部编码实现：</p>
<ul>
<li><code>ziplist</code>(<strong>压缩列表</strong>)：当哈希类型元素个数小于<code>zset-max-ziplist-entries</code>配置（默认128个），同时所有值小于<code>zset-max-ziplist-value</code>配置（默认64）时，使用<code>ziplist</code>作为内部实现，<code>ziplist</code>使用更加紧凑的结构实现多个元素的连续存储，在节省内存方面更加优秀。</li>
<li><code>skiplist</code>(<strong>跳表</strong>)：当<code>ziplist</code>条件不满足时，有序集合会使用<code>skiplist</code>作为内部实现，因为此时<code>ziplist</code>的读写效率会下降</li>
</ul>
<h3 id="各个指令的时间复杂度-4"><a href="#各个指令的时间复杂度-4" class="headerlink" title="各个指令的时间复杂度"></a>各个指令的时间复杂度</h3><ul>
<li><strong>ZADD</strong>：向指定 Sorted Set 中添加 1 个或多个 member，时间复杂度 <code>O(Mlog(N))</code>，M 为添加的 member 数量，N 为 Sorted Set 中的 member 数量</li>
<li><strong>ZREM</strong>：从指定 Sorted Set 中删除 1 个或多个 member，时间复杂度 <code>O(Mlog(N))</code>，M 为删除的 member 数量，N 为 Sorted Set 中的 member 数量</li>
<li><strong>ZCOUNT</strong>：返回指定 Sorted Set 中指定 score 范围内的 member 数量，时间复杂度：<code>O(log(N))</code></li>
<li><strong>ZCARD</strong>：返回指定 Sorted Set 中的 member 数量，时间复杂度 <code>O(1)</code></li>
<li><strong>ZSCORE</strong>：返回指定 Sorted Set 中指定 member 的 score，时间复杂度 <code>O(1)</code></li>
<li><strong>ZRANK/ZREVRANK</strong>：返回指定 member 在 Sorted Set 中的排名，ZRANK 返回按升序排序的排名，ZREVRANK 则返回按降序排序的排名。时间复杂度 <code>O(log(N))</code></li>
<li><strong>ZINCRBY</strong>：同 INCRBY，对指定 Sorted Set 中的指定 member 的 score 进行自增，时间复杂度 <code>O(log(N))</code></li>
</ul>
<p>慎用的Sorted Set相关命令：</p>
<ul>
<li><strong>ZRANGE/ZREVRANGE</strong>：返回指定 Sorted Set 中指定排名范围内的所有 member，ZRANGE 为按 score 升序排序，ZREVRANGE 为按 score 降序排序，时间复杂度 <code>O(log(N)+M)</code>，M为本次返回的 member 数</li>
<li><strong>ZRANGEBYSCORE/ZREVRANGEBYSCORE</strong>：返回指定 Sorted Set 中指定 score 范围内的所有 member，返回结果以升序/降序排序，min 和 max 可以指定为 -inf和+ inf，代表返回所有的 member。时间复杂度 <code>O(log(N)+M)</code></li>
<li><strong>ZREMRANGEBYRANK/ZREMRANGEBYSCORE</strong>：移除 Sorted Set 中指定排名范围/指定 score 范围内的所有 member。时间复杂度 <code>O(log(N)+M)</code></li>
</ul>
<p>上述几个命令，应尽量避免传递 <code>[0 -1]</code> 或 <code>[-inf +inf]</code> 这样的参数，来对 Sorted Set 做一次性的完整遍历，特别是在 Sorted Set 的尺寸不可预知的情况下。可以通过 ZSCAN 命令来进行游标式的遍历，或通过 LIMIT 参数来限制返回 member 的数量（适用于 ZRANGEBYSCORE 和 ZREVRANGEBYSCORE 命令），以实现游标式的遍历。</p>
<h2 id="Bitmaps"><a href="#Bitmaps" class="headerlink" title="Bitmaps"></a>Bitmaps</h2><p>计算机使用二进制位（位）作为信息的基础单位，1个字节等于8位，Redis 提供 Bitmaps 可以实现对位的操作。Bitmaps 本身不是一种数据结构，实际上它是字符串，但可以对字符串的位进行操作</p>
<p>可以把 Bitmaps 看成一个以位为单位的数组，数组的每个单元只能存储 0 和 1，数组的下标在 Bitmaps 中叫做偏移量</p>
<h3 id="常用指令"><a href="#常用指令" class="headerlink" title="常用指令"></a>常用指令</h3><ul>
<li><code>setbit key offset value</code>：设置键的第 offset 个位的值</li>
<li><code>getbit key offset</code>：获取值</li>
<li><code>bitcount [start][end]</code>：获取 Bitmaps 指定范围值为 1 的个数,其中 start 和 end 代表起始和结束字节数（一个字节占8位，例如start=2表示从下标16开始算）</li>
</ul>
<p>Bitmaps 间的运算：</p>
<ul>
<li><code>bitop op destkey key[key …]</code>：op可以是and（交集），or（并集），not（非），xor（异或）操作， 操作结果保存在 deskey 中</li>
<li><code>bitpos key targetBit [start][end]</code>:计算 Bitmaps 中第一个值为targetBit的偏移量</li>
</ul>
<p>应用场景：<br>当用户量很大时，用来记录当天访问人数，可以大幅度减少内存</p>
<h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><p>HyperLogLog 实际类型为字符串类型，它是一种基数算法，可以利用极小的内存空间独立完成总数的统计</p>
<ul>
<li><code>pfadd key element [element …]</code>：添加</li>
<li><code>pfcount key [key …]</code>：计算独立用户数</li>
<li><code>pfmerge destkey sourcekey [sourcekey …]</code>：合并:求出多个 HyperLogLog 的并集并赋值给 deskey</li>
</ul>
<p>HyperLogLog 内存占用量非常小，但是存在错误率</p>
<h1 id="2-为什么要用redis-为什么要用缓存"><a href="#2-为什么要用redis-为什么要用缓存" class="headerlink" title="2. 为什么要用redis/为什么要用缓存"></a>2. 为什么要用redis/为什么要用缓存</h1><p>主要从“高性能”和“高并发”这两个点来看待这个问题</p>
<p><strong>高性能</strong>：</p>
<p>Redis中的数据是存储在内存中的，所以读写速度非常快。假如用户第一次访问数据库中的某些数据，这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变之后，同步改变缓存中相应的数据即可。</p>
<p><strong>高并发</strong>：</p>
<p>直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库</p>
<h1 id="3-为什么使用redis而不直接在程序中使用map-guava做缓存？"><a href="#3-为什么使用redis而不直接在程序中使用map-guava做缓存？" class="headerlink" title="3. 为什么使用redis而不直接在程序中使用map/guava做缓存？"></a>3. 为什么使用redis而不直接在程序中使用map/guava做缓存？</h1><p>缓存分为本地缓存和分布式缓存，以Java为例，使用自带得<code>map</code>或者<code>guava</code>实现的是本地缓存，最主要得特点是<strong>轻量以及快速</strong>，生命周期随着JVM的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，<strong>缓存不具有一致性</strong>。</p>
<p>使用<code>redis</code>或<code>memcached</code>之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持<code>redis</code>或<code>memcached</code>服务的高可用，整个程序架构上较为复杂。</p>
<h1 id="4-redi的线程模型"><a href="#4-redi的线程模型" class="headerlink" title="4. redi的线程模型"></a>4. redi的线程模型</h1><p>redis内部使用文件事件处理器<code>file event handler</code>,这个文件事件处理器是单线程的，所以redis才叫做单线程的模型。它采用IO多路复用机制同时监听多个socket，根据socket上的事件来选择对应的事件处理器进行处理。</p>
<p>文件事件处理器的结构包含4各部分：</p>
<ul>
<li>多个socket</li>
<li>IO 多路复用程序</li>
<li>文件事件分派器</li>
<li>事件处理器（连接应答处理器，命令请求处理器、命令回复处理器）</li>
</ul>
<p>多个socket可能会并发产生不同的操作，每个操作对应不同的文件事件，但是IO多路服用程序会监听多个socket，会将socket产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。</p>
<p>客户端与redis的一次通信过程如下：</p>
<p><img src="http://qiniu.xiaoming.net.cn/Redis%E4%B8%80%E6%AC%A1%E9%80%9A%E8%A1%8C%E8%BF%87%E7%A8%8B.webp" alt="redis的一次通信过程"></p>
<p>客户端<code>socket01</code>向redis的<code>server socket</code>请求建立连接，此时<code>server socket</code>会产生一个<code>AE_READBLE</code>事件，IO多路复用程序监听到<code>server socket</code>产生的事件后，将该事件压入队列中。文件事件分派器从队列中获取该事件，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的<code>socket01</code>,并将该<code>socket01</code>的<code>AE_READBLE</code>事件与命令请求处理器相关联。</p>
<p>假设此时客户端发送了一个<code>set key value</code>请求，此时redis的<code>socket01</code>会产生<code>AE_READABLE</code>事件，IO多路复用程序将事件压入队列，此时事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取<code>socket01</code>中的<code>key value</code>并在自己内存中完成<code>key value</code>的设置。操作完成后，它会将<code>socket01</code>的<code>AE_WRITABLE</code>事件与命令回复处理器相关联。</p>
<p>如果此时客户端准备好接收返回结果了，那么redis中的<code>socket01</code>会产生一个<code>AE_WRITABLE</code>事件，同样压入队列中，事件分派器找到相关联的的命令回复处理器，由命令回复处理器对<code>socket01</code>输入本次操作的一个结果，比如<code>ok</code>，之后解除<code>socket01</code>的<code>AE_WRITABLE</code>事件与命令回复处理器的关联。</p>
<p>这就完成了一次通信。</p>
<h1 id="5-redis和memcached的区别"><a href="#5-redis和memcached的区别" class="headerlink" title="5. redis和memcached的区别"></a>5. redis和memcached的区别</h1><ul>
<li><strong>Redis支持更丰富的数据类型（支持更复杂的应用场景）</strong>：Redis不仅仅支持简单的<code>k/v</code>类型的数据，同时还提供<code>list</code>,<code>hash</code>,<code>set</code>,<code>zset</code>等数据结构的存储。memcached支持简单数据类型难过<code>String</code>。</li>
<li><strong>Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而Memcached把数据全部存在内存之中</strong></li>
<li><strong>集群模式</strong>：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是redis目前是原生支持<code>cluster</code>模式的</li>
<li><strong>Memcached是多线程的，非阻塞IO复用的网络模型；Redis使用单线程的多路复用IO模型</strong></li>
</ul>
<h1 id="6-redis过期键处理方式"><a href="#6-redis过期键处理方式" class="headerlink" title="6. redis过期键处理方式"></a>6. redis过期键处理方式</h1><p>Redis中有个设置时间过期的功能，即对存储在 redis 数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如一般项目中的<code>token</code> 或者一些登录信息，尤其是短信验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。</p>
<p>在<code>set key</code>的时候，都可以给一个<code>expire time</code>，就是过期时间，通过过期时间可以指定这个<code>key</code>可以存活的时间。</p>
<p>Redis对过期的键采用的删除方式是：<strong>定期删除+惰性删除</strong></p>
<ul>
<li><strong>定期删除</strong>：redis默认是每隔100ms就随机抽取一些设置了过期时间的<code>key</code>,检查其是否过期，如果过期就删除。注意这里是随机抽取的。采用随机抽取的方式是因为如果Redis存了很多<code>key</code>的话，每隔100ms就遍历所有的设置过期时间的<code>key</code>的话，就会给CPU带来很大的负载。</li>
<li><strong>惰性删除</strong>：定期删除可能会导致很多过期<code>key</code>到了时间并没有被删除掉。所以就有了惰性删除。对于过期的<code>key</code>,如果过了时间还没有被定期删除，还停留在内存中，只有在系统中查询一下这个<code>key</code>，redis才会把它给删除掉，这就是所谓的惰性删除。</li>
</ul>
<p>但是仅仅通过设置过期时间还是有问题的。如果定期删除漏掉了很多过期<code>key</code>，然后也没及时去查，也就没走惰性删除，此时会有大量过期key堆积在内存里，导致redis内存块耗尽了。redis采用<strong>内存淘汰机制</strong>进行处理。</p>
<h1 id="7-redis内存淘汰机制（MySQL中有2000w数据，Redis中只存了20w数据，如何保证Redis中的数据都是热点数据？）"><a href="#7-redis内存淘汰机制（MySQL中有2000w数据，Redis中只存了20w数据，如何保证Redis中的数据都是热点数据？）" class="headerlink" title="7. redis内存淘汰机制（MySQL中有2000w数据，Redis中只存了20w数据，如何保证Redis中的数据都是热点数据？）"></a>7. redis内存淘汰机制（MySQL中有2000w数据，Redis中只存了20w数据，如何保证Redis中的数据都是热点数据？）</h1><p>当Redis中内存使用量超出时，会施行数据淘汰策略</p>
<p>Redis支持6种淘汰策略：</p>
<ul>
<li><strong>volatile-lru</strong>：从已设置过期时间的数据集(<code>server.db[i].expires</code>)中挑选最近最少使用的数据淘汰</li>
<li><strong>volatile-ttl</strong>：从已设置过期时间的数据集(<code>server.db[i].expires</code>)中挑选将要过期的数据淘汰</li>
<li><strong>volatile-random</strong>：从已设置过期时间的数据集(<code>server.db[i].expires</code>)中任意选择数据淘汰</li>
<li><strong>allkeys-lru</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的<code>key</code>(这个是最常用的)</li>
<li><strong>allkeys-random</strong>：从数据集(<code>server.db[i].dict</code>)中任意选择数据淘汰</li>
<li><strong>no-eviction</strong>:禁止驱逐数据，也就是说当内存不足以容纳新写入的数据时，新写入操作会报错。</li>
</ul>
<p>4.0版本以后增加了以下两种：</p>
<ul>
<li><strong>volatile-lfu</strong>：从已设置过期时间的数据集(<code>server.db[i].expires</code>)中挑选最不经常使用的数据淘汰</li>
<li><strong>allkeys-lfu</strong>：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的<code>key</code></li>
</ul>
<h1 id="8-Redis数据持久化（怎么保证Redis挂掉之后再重启数据不会丢失）"><a href="#8-Redis数据持久化（怎么保证Redis挂掉之后再重启数据不会丢失）" class="headerlink" title="8. Redis数据持久化（怎么保证Redis挂掉之后再重启数据不会丢失）"></a>8. Redis数据持久化（怎么保证Redis挂掉之后再重启数据不会丢失）</h1><p>Redis支持两种持久化方案，分别是<strong>RDB（快照）</strong>和<strong>AOF（只追加文件）</strong></p>
<h2 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h2><p>Redis可以通过创建快照来获得存储在内存里面的数据<strong>在某个时间点上的副本</strong>。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。快照持久化是Redis默认采用的持久化方式。</p>
<h3 id="触发机制"><a href="#触发机制" class="headerlink" title="触发机制"></a>触发机制</h3><h4 id="手动触发"><a href="#手动触发" class="headerlink" title="手动触发"></a>手动触发</h4><ul>
<li><code>save</code>:阻塞当前Redis，直到RDB过程完成，对于内存比较大的实例会造成阻塞，已经被淘汰</li>
<li><code>bgsave</code>:Redis进行执行<code>fork</code>操作创建子进程，RDB持久化过程由子进程完成，完成后自动结束，阻塞只发生在<code>fork</code>阶段，一般时间很短。</li>
</ul>
<h4 id="自动触发"><a href="#自动触发" class="headerlink" title="自动触发"></a>自动触发</h4><ol>
<li>使用<code>save</code>相关配置，会自动出发<code>bgsave</code>,在<code>redis.conf</code>配置文件中默认有此下配置：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br><span class="line"></span><br><span class="line">save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br><span class="line"></span><br><span class="line">save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br></pre></td></tr></table></figure></li>
<li>如果从节点执行全量复制操作，主节点自动执行<code>bgsave</code>生成RDB文件并发送给从节点</li>
<li>执行<code>debug reload</code>命令时重新加载Redis时，也会自动触发<code>save</code>操作</li>
<li>默认情况下执行<code>shutdown</code>命令，如果没有开启AOF持久化功能则自动执行<code>bgsave</code></li>
</ol>
<h3 id="流程说明"><a href="#流程说明" class="headerlink" title="流程说明"></a>流程说明</h3><p><code>bgsave</code>执行的流程如下：</p>
<ol>
<li>执行<code>bgsave</code>命令，Redis父进程判断当前是否存在正在执行的子进程，如果<code>RDB/AOF</code>子进程存在则直接返回</li>
<li>父进程执行<code>fork</code>操作创建子进程，<code>fork</code>操作过程父进程会阻塞，通过<code>info stats</code>查看<code>latest_fork_usec</code>选项，获得最近一个<code>fork</code>操作的耗时，单位为微秒</li>
<li>父进程<code>fork</code>完成后，<code>bgsave</code>命令返回<code>Background saving started</code>信息并不再阻塞父进程，可以继续响应其他命令</li>
<li>子进程创建RDB文件，根据父进程内存生成的临时快照文件，完成后对原有文件进行原子替换，执行<code>lastsave</code>可以获取最后一次生成RDB的事件，对应<code>info</code>统计的<code>rdb_last_save_time</code></li>
<li>进程发送信号给父进程表示完成，父进程更新统计信息，存放在<code>info</code>的<code>Persistence</code>下。</li>
</ol>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li>RDB是一个紧凑压缩的二进制文件，代表Redis在某个时间点上的一个数据快照，非常适用于备份，全量复制等场景</li>
<li>Redis加载RDB恢复数据远远快于AOF的方式</li>
</ul>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>没法做到实时持久化/秒级持久化</li>
<li>RDB使用特定的二进制格式保存，Redis演变过程中有很多RDB版本，存在老版本无法兼容新版本的问题</li>
<li>如果数据量很大，保存快照的时间会很长。</li>
</ul>
<h2 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h2><p>以独立日志的方式记录每次写命令，将写命令添加到 AOF 文件（Append Only File）的末尾。重启时再重新执行AOF文件中的命令达到恢复数据的目的。AOF的主要作用是解决数据持久化的实时性，因此已成为主流的持久化方案。</p>
<p>默认情况下Redis没有开启AOF方式的持久化，可以通过以下配置开启：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendonly yes</span><br></pre></td></tr></table></figure>

<p>开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是<code>appendonly.aof</code>。</p>
<h3 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h3><ol>
<li>写入命令(<code>append</code>):所有的写入命令都会追加到<code>aof_buf</code>缓冲区</li>
<li>文件同步(<code>aync</code>):AOF缓冲区根据对应的策略向硬盘做同步操作</li>
<li>文件重写(<code>rewrite</code>):随着AOF文件越来越大，定期对AOF文件进行重写，达到压缩的目的</li>
<li>重启加载(<code>load</code>):当Redis服务器重启时，可以加载AOF文件进行数据恢复</li>
</ol>
<p>在Redis的配置文件中存在三种不同的 AOF 持久化同步策略，它们分别是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度</span><br><span class="line">appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘</span><br><span class="line">appendfsync no        #让操作系统决定何时进行同步</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>always</strong>：写入<code>aof_buf</code>后调用系统<code>fsync</code>操作同步到AOF文件，<code>fsync</code>完成后线程返回；每次写入都要进行文件同步，严重降低Redis速度，一般不建议使用</li>
<li><strong>everysec</strong>：命令写入<code>aof_buf</code>后调用系统<code>write</code>操作，完成后线程返回。<code>fsync</code>同步文件操作由专门线程每秒调用一次；建议的策略，<strong>理论上在系统突然宕机的情况下会丢失1秒数据</strong>，<code>fsync</code>完成后会与上次<code>fsync</code>时间做对比，超过两秒后主线程阻塞，直到同步操作完成,<strong>因此最多可能丢失2秒数据，不是1秒</strong></li>
<li><code>no</code>:命令写入<code>aof_buf</code>后调用系统<code>write</code>操作，不对AOF文件做<code>fsync</code>同步，同步硬盘操作由操作系统负责，通常同步周期最长30秒，周期不可控，加大每次同步的数据量，虽然提升了性能，安全性无法保证</li>
</ul>
<h3 id="Redis-4-0-对于持久化机制的优化"><a href="#Redis-4-0-对于持久化机制的优化" class="headerlink" title="Redis 4.0 对于持久化机制的优化"></a>Redis 4.0 对于持久化机制的优化</h3><p>Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项<code>aof-use-rdb-preamble</code>开启）。</p>
<p>如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。</p>
<h3 id="AOF重写机制"><a href="#AOF重写机制" class="headerlink" title="AOF重写机制"></a>AOF重写机制</h3><p>随着命令不断写入AOF，文件会越来越大，Redis引入重写机制压缩文件体积，AOF文件重写是把Redis进程内的数据转化为写命令同步到新AOF文件的过程<br>重写后AOF文件变小的原理：</p>
<ul>
<li>进程内已经超时的数据不再写入文件</li>
<li>旧的AOF文件含有无效命令，如<code>del key</code>，<code>hdel key2</code>，<code>srem keys</code>，<code>set a1</code>，<code>set a2</code>等，重写时使用进程内的数据直接生成，这样新的AOF文件只保留最终数据的写入命令</li>
<li>多条写的命令合并为一条，如<code>lpush list a</code>，<code>lpush list b</code>转化为<code>lpush list a b</code>，为了防止过多造成客户端缓冲区溢出，以64个元素为界拆分多条</li>
</ul>
<p><strong>重写的优点</strong>：降低文件占用空间，更快的被Redis加载</p>
<h4 id="重写过程的触发："><a href="#重写过程的触发：" class="headerlink" title="重写过程的触发："></a>重写过程的触发：</h4><ul>
<li><strong>手动触发</strong>：使用<code>bgrewriteaof</code>命令</li>
<li><strong>自动触发</strong>：配置文件配置<code>auto-aof-rewrite-min-size</code>,<code>auto-aof-rewrite-percentage</code>,前者表示AOF重写时文件最小体积，默认64MB，后者代表AOF文件空间（<code>aof_current_size</code>）和上一次重写后AOF文件空间（<code>aof_base_size</code>）的比值</li>
</ul>
<h4 id="重写流程"><a href="#重写流程" class="headerlink" title="重写流程"></a>重写流程</h4><ol>
<li>执行AOF重写请求，如果当前进程正在执行AOF重写，请求不执行；如果当前进程正在执行<code>bgsave</code>操作，重写命令延迟到<code>bgsave</code>完成之后再执行</li>
<li>父进程执行fork创建子进程，开销等同于<code>bgsave</code></li>
<li>(1).主进程<code>fork</code>操作完成后，继续响应其他命令，所有修改命令依然写入AOF缓冲区并根据<code>appendfsync</code>策略同步到硬盘，保证原有AOF机制正确性<br>(2).由于<code>fork</code>操作运用写时复制技术，子进程只能共享<code>fork</code>操作时的内部数据。由于父进程依然响应命令，Redis使用<strong>AOF重写缓冲区</strong>保证这部分新数据，防止新的AOF文件生成期间丢失这部分数据</li>
<li>子进程根据内存快照，按照命令合并规则写入到新的AOF文件，每次批量写入硬盘数据量由配置<code>aof-rewrite-incremental-fsync</code>控制，默认32MB，防止单次刷盘数据过多造成硬盘阻塞</li>
<li>(1). 新AOF文件写入完成后，子进程发送信号给父进程，父进程更新统计信息<br>(2). 父进程把AOF重写缓冲区的数据写入到新的AOF文件<br>(3). 使用新的AOF文件替换老文件，重写完成</li>
</ol>
<h1 id="9-Redis事务"><a href="#9-Redis事务" class="headerlink" title="9. Redis事务"></a>9. Redis事务</h1><p>Redis提供了简单的事务功能，将一组需要执行的命令放到<code>multi</code>和<code>exec</code>之间，<code>multi</code>代表事务开始，<code>exec</code>代表事务结束，只有执行了<code>exec</code>后中间的命令才会被执行</p>
<p>如果要停止事务的执行，可以使用<code>discard</code>命令代替<code>exec</code></p>
<p>事务中出现错误的情况：</p>
<ul>
<li><strong>命令错误</strong>：例如语法错误，会导致整个事务无法执行</li>
<li><strong>运行时错误</strong>：例如错将<code>sadd</code>写成<code>zadd</code>，这时候执行<code>exec</code>时<strong>正确的命令会被执行，Redis不支持回滚功能</strong></li>
</ul>
<p>在事务之前如果需要确保事务中的<code>key</code>没有被其他客户端修改才能执行，否则不执行（乐观锁），可以通过在<code>multi</code>之前先执行<code>watch</code>命令来实现</p>
<p>在传统的关系式数据库中，常常用 ACID 性质来检验事务功能的可靠性和安全性。在 Redis 中，事务总是具有原子性（Atomicity）、一致性（Consistency）和隔离性（Isolation），并且当 Redis 运行在某种特定的持久化模式下时，事务也具有持久性（Durability）。</p>
<h1 id="10-缓存雪崩问题解决方案"><a href="#10-缓存雪崩问题解决方案" class="headerlink" title="10. 缓存雪崩问题解决方案"></a>10. 缓存雪崩问题解决方案</h1><p>缓存雪崩指的是缓存同一时间大面积的失效，所以后面的请求都会落到数据库上，造成数据库短时间内承受大量的请求而崩掉。</p>
<p>解决方案：</p>
<ul>
<li>事前：尽量保证整个Redis集群的高可用性，发现机器宕机尽快补上，选择合适的内存淘汰策略</li>
<li>事中：<strong>本地ehcache缓存+hystrix限流&amp;降级</strong>，避免MySQL崩掉</li>
<li>事后：利用redis持久化机制保存的数据尽快恢复缓存</li>
</ul>
<p><img src="http://qiniu.xiaoming.net.cn/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.jpeg" alt="缓存雪崩解决方案"></p>
<h1 id="11-缓存穿透问题解决方案"><a href="#11-缓存穿透问题解决方案" class="headerlink" title="11. 缓存穿透问题解决方案"></a>11. 缓存穿透问题解决方案</h1><p>缓存穿透：一般是黑客故意去请求缓存中不存在的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p>
<p>解决办法： 有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。</p>
<h1 id="12-如何解决Redis的并发竞争key问题"><a href="#12-如何解决Redis的并发竞争key问题" class="headerlink" title="12. 如何解决Redis的并发竞争key问题"></a>12. 如何解决Redis的并发竞争key问题</h1><p>所谓Redis的并发竞争Key的问题也就是多个系统同时对一个Key进行操作，但是最后执行的顺序和期望的顺序不同，这样也就导致了结果的不同。</p>
<p>解决方案：可以使用分布式锁（<code>Zookeeper</code>和 redis 都可以实现分布式锁）。（如果不存在Redis的并发竞争Key问题，不要使用分布式锁，这样会影响性能）</p>
<p>基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在<code>zookeeper</code>上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。</p>
<p>在实践中，当然是以可靠性为主,所以首推Zookeeper。</p>
<h1 id="13-如何保证缓存与数据库双写时的数据一致性？"><a href="#13-如何保证缓存与数据库双写时的数据一致性？" class="headerlink" title="13. 如何保证缓存与数据库双写时的数据一致性？"></a>13. 如何保证缓存与数据库双写时的数据一致性？</h1><p>只要用缓存，就可能会涉及到缓存与数据库双存储，双写，只要是双写，就一定会有数据一致性问题，如何解决呢？</p>
<p>一般来说，如果系统不是严格要求缓存+数据库必须一致性的话，缓存可以稍微跟数据库偶尔有不一致的情况。</p>
<p>另外，可以将读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况，但是串行化之后，就会导致系统的吞吐量大幅度降低，需要用比正常情况下多几倍的机器去支撑线上的一个请求。</p>
<p>解决这个问题的最经典的模式，就是 Cache Aside Pattern 数据库读写模式。</p>
<ol>
<li>读的时候先读缓存，如果缓存不存在的话就读数据库，取出数据库后更新缓存；如果存在的话直接读取缓存的信息。</li>
<li>写的时候，先更新数据库，再删除缓存。</li>
</ol>
<h2 id="为什么是删除缓存而不是更新缓存？"><a href="#为什么是删除缓存而不是更新缓存？" class="headerlink" title="为什么是删除缓存而不是更新缓存？"></a>为什么是删除缓存而不是更新缓存？</h2><p>很多时候复杂的缓存场景，缓存不是仅仅从数据库中取出来的值。可能是关联多张表的数据并通过计算才是缓存需要的值。并且，更新缓存的代价有时候很高。<strong>对于需要频繁写操作，而读操作很少的时候，每次进行数据库的修改，缓存也要随之更新，会造成系统吞吐的下降，但此时缓存并不会被频繁访问到，用到的缓存才去算缓存</strong>。</p>
<p>删除缓存而不是更新缓存，是一种懒加载的思想，不是每次都重复更新缓存，只有用到的时候才去更新缓存，同时即使有大量的读请求，实际也就更新了一次，后面的请求不会重复读。</p>
<h2 id="Cache-Aside-Pattern存在的问题"><a href="#Cache-Aside-Pattern存在的问题" class="headerlink" title="Cache Aside Pattern存在的问题"></a>Cache Aside Pattern存在的问题</h2><p>问题：先更新数据库，再删除缓存，如果删除缓存失败了，导致数据库中是新数据，缓存中是旧数据，就出现数据不一致的问题。</p>
<p><strong>解决思路</strong>：先删除缓存，再更新数据库。</p>
<ul>
<li>缓存删除失败：如果缓存删除失败，那么就不会继续执行，数据库信息没有被修改，保持了数据的一致性；</li>
<li>缓存删除成功，数据库更新失败：此时数据库里的是旧数据，缓存是空的，查询时发现缓存不存在，就查询数据库并更新缓存，数据保持一致。</li>
</ul>
<p>问题：上面的方案存在不足，如果删除完缓存更新数据库时，如果一个请求过来查询数据，缓存不存在，就查询数据库的旧数据，更新旧数据到缓存中。随后数据更新完成，修改了数据库的数据，此时缓存和数据库的数据就会出现不一致了。高并发下会出现这种数据库 + 缓存不一致的情况。 如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。</p>
<p><strong>解决方案</strong>：采用双删除策略。写请求先删除缓存，再去更新数据库，等待一段时间后异步删除缓存。这样可以保证在读取错误数据时能及时被修正过来。</p>
<p>还有一种策略，就是：写请求先修改缓存为指定值，然后再去更新数据库，再更新缓存。读请求过来后，会先读缓存，判断是指定值后就进入循环读取状态，等到写请求更新缓存。如果循环超时就去数据库读取数据，更新缓存。</p>
<p>这种方案保证了读写的一致性，但由于读请求等待写请求的完成，会降低系统的吞吐量。</p>
<h1 id="14-Redlock分布式锁"><a href="#14-Redlock分布式锁" class="headerlink" title="14. Redlock分布式锁"></a>14. Redlock分布式锁</h1><p>Redis官方提出一种基于Redis实现的分布式锁的方式叫<code>Redlock</code>,这种方法比原先单节点的方法更安全。它可以保证以下特性：</p>
<ul>
<li>安全特性：互斥访问，即永远只有一个<code>client</code>能拿到锁</li>
<li>避免死锁：最终<code>client</code>都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的<code>client</code>crash了或者出现了网络分区</li>
<li>容错性：只要大部分Redis节点存活剧可以正常提供服务</li>
</ul>
<h2 id="怎么在单点上实现分布式锁"><a href="#怎么在单点上实现分布式锁" class="headerlink" title="怎么在单点上实现分布式锁"></a>怎么在单点上实现分布式锁</h2><p>主要通过以下命令:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET resource_name my_random_value NX PX 30000</span><br></pre></td></tr></table></figure>
<p>该命令仅当key不存在（NX保证）时，<code>set</code>值，并且设置过期时间为<code>3000ms</code>(PX保证)，值<code>my_random_value</code>必须是所有<code>client</code>和所有锁请求发生期间唯一的，释放锁的逻辑是：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> redis.call(<span class="string">"get"</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">"del"</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>上述实现避免了释放另一个<code>client</code>创建的锁，如果只有<code>del</code>命令的话，如果<code>client1</code>拿到<code>lock1</code>之后因为某些操作阻塞了很长时间，此时Redis端<code>lock1</code>已经过期了并且已经被重新分配给了<code>client2</code>,那么<code>client1</code>此时再去释放这把锁就会造成<code>client2</code>原本获取到的锁被<code>client1</code>无故释放了，但现在为每个<code>client</code>分配一个<code>uniqu</code>的<code>string</code>值可以避免这个问题。至于如何去生成这个<code>unique string</code>，方法很多随意选择一种就行了。</p>
<h2 id="Redlock算法"><a href="#Redlock算法" class="headerlink" title="Redlock算法"></a>Redlock算法</h2><p>假设有5个<code>master</code>节点，分布在不同的机房，为了获得锁，<code>client</code>会进行如下操作：</p>
<ol>
<li>得到当前的事件，微秒单位</li>
<li>尝试顺序的在5个实例上申请锁，当然需要使用相同的<code>key</code>和<code>random value</code>,这里一个<code>client</code>需要合理设置与<code>master</code>节点沟通的<code>timeout</code>大小，避免长时间和一个<code>fail</code>的节点浪费时间</li>
<li>当<code>client</code>在大于等于 3 个<code>master</code>上成功申请到锁的时候，且它会计算申请锁消耗了多少时间，这部分消耗的时间采用获得锁的当下时间减去第一步获得的时间戳得到，如果锁的持续时长（lock validity time）比流逝的时间多的话，那么锁就真正获取到了。</li>
<li>如果锁申请到了，那么锁真正的<code>lock validity time</code>应该是<code>origin（lock validity time） - 申请锁期间流逝的时间</code></li>
<li>如果<code>client</code>申请锁失败了，那么它就会在少部分申请成功锁的<code>master</code>节点上执行释放锁的操作，重置状态。</li>
</ol>
<blockquote>
<p>这个算法是基于一个假设：虽然不存在可以跨进程的同步时钟，但是不同进程时间都是以差不多相同的速度前进，这个假设不一定完全准确，但是和自动释放锁的时间长度相比不同进程时间前进速度差异基本是可以忽略不计的。</p>
</blockquote>
<h2 id="失败重试"><a href="#失败重试" class="headerlink" title="失败重试"></a>失败重试</h2><p>如果一个<code>client</code>申请锁失败了，那么它需要稍等一会再重试避免多个<code>client</code>同时申请锁的情况，最好的情况是一个<code>client</code>需要几乎同时向5个<code>master</code>发起申请锁申请。另外就是如果<code>client</code>申请锁失败了它需要尽快在它曾经申请到锁的<code>master</code>上执行<code>unlock</code>操作，便于其它<code>client</code>获取这把锁，避免这些锁过期造成的时间浪费，当然如果这时候网络分区使得<code>client</code>无法联系上这些<code>master</code>,那么这种浪费就是不得不付出的代价了。</p>
<h2 id="放锁"><a href="#放锁" class="headerlink" title="放锁"></a>放锁</h2><p>放锁操作很简单，就是依次释放所有节点上的锁就行了</p>
<h2 id="性能、崩溃恢复和fsync"><a href="#性能、崩溃恢复和fsync" class="headerlink" title="性能、崩溃恢复和fsync"></a>性能、崩溃恢复和fsync</h2><p>如果节点没有持久化机制，<code>client</code>从 5 个<code>master</code>中的 3 个处获得了锁，然后其中一个重启了，这时注意整个环境中又出现了 3 个<code>master</code>可供另一个<code>client</code>申请同一把锁！ 违反了互斥性。如果开启了 AOF 持久化那么情况会稍微好转一些，因为 Redis 的过期机制是语义层面实现的，所以在<code>server</code>挂了的时候时间依旧在流逝，重启之后锁状态不会受到污染。但是考虑断电之后呢，AOF部分命令没来得及刷回磁盘直接丢失了，除非配置刷回策略为<code>fsnyc = always</code>，但这会损伤性能。解决这个问题的方法是，当一个节点重启之后，规定在<code>max TTL</code>期间它是不可用的，这样它就不会干扰原本已经申请到的锁，等到它<code>crash</code>前的那部分锁都过期了，环境不存在历史锁了，那么再把这个节点加进来正常工作。</p>
<h2 id="RedLock缺陷"><a href="#RedLock缺陷" class="headerlink" title="RedLock缺陷"></a>RedLock缺陷</h2><p>需要用到锁的主要有以下两种场景考虑：</p>
<ul>
<li><strong>性能</strong>：拥有这把锁使得你不会重复劳动（例如一个job做了两次），如果这把锁fail了，两个节点同时做了这个job，那么这个job增加了你的成本</li>
<li><strong>正确性</strong>：拥有锁可以防止并发操作污染了你的系统或者数据，如果这把锁fail了，两个节点同时操作了一份数据，结果可能是数据不一致、数据丢失、file冲突等，会导致严重的后果</li>
</ul>
<h3 id="RedLock算法不可靠的场景"><a href="#RedLock算法不可靠的场景" class="headerlink" title="RedLock算法不可靠的场景"></a>RedLock算法不可靠的场景</h3><p>在分布式环境下，锁比<code>mutex</code>这类复杂，因为涉及到不同节点、网络通信并且他们随时可能无征兆的fail。假设现在有一个场景：一个client要修改一个文件，它先申请得到锁，然后修改文件写回，放锁。另一个client再申请锁。代码流程如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">function <span class="title">writeData</span><span class="params">(filename,data)</span></span>&#123;</span><br><span class="line">    <span class="keyword">var</span> lock = lockService.acquireLock(filename);</span><br><span class="line">    <span class="keyword">if</span>(!lock) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="string">'Failed to acquire lock!'</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">var</span> file = storage.readFile(filename);</span><br><span class="line">        <span class="keyword">var</span> updated = updateContents(file,data);</span><br><span class="line">        sotrage.writeFile(filename,updated);</span><br><span class="line">    &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">        lock.release();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述代码在以下流程中还是有可能出现bug：</p>
<p><img src="https://camo.githubusercontent.com/b1fd3e057266f0ca21f69e2a26f420f9564c5cdb/68747470733a2f2f6d617274696e2e6b6c6570706d616e6e2e636f6d2f323031362f30322f756e736166652d6c6f636b2e706e67" alt="RedLock锁流程"></p>
<p>在上述图中，得到锁的client1在持有锁的期间pause（暂停）了一段时间，例如GC停顿。锁有过期时间（一般叫租约，为了防止某个 client 崩溃之后一直占有锁），但是如果 GC 停顿太长超过了锁租约时间，此时锁已经被另一个 client2 所得到，原先的 client1 还没有感知到锁过期，这时候client再进行写时就会发生错误。即使在client1写回之前检查一下锁是否过期也无法解决这个问题，因为GC可能在任何时候发生，即使在最后的检查和写操作期间。</p>
<p>除了GC停顿，还有很多原因可能导致进程pause。例如进程可能读取尚未进入内存的数据，所以它得到一个 page fault （错误页面）并且等待 page 被加载进缓存；还有可能你依赖于网络服务；或者其他进程占用 CPU；或者其他意外发生 SIGSTOP 等。</p>
<h3 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h3><h4 id="使用Fencing（栏栅）使锁变安全"><a href="#使用Fencing（栏栅）使锁变安全" class="headerlink" title="使用Fencing（栏栅）使锁变安全"></a>使用Fencing（栏栅）使锁变安全</h4><p>在每次写操作时加入一个<code>fencing token</code>,这个场景下，<code>fencing token</code>可以是一个递增的数字（lock service可以做到），每次有client申请锁就递增一次：</p>
<p><img src="https://camo.githubusercontent.com/4ca3c6919e560b60b130c4f856d2736314713e62/68747470733a2f2f6d617274696e2e6b6c6570706d616e6e2e636f6d2f323031362f30322f66656e63696e672d746f6b656e732e706e67" alt="使用Fencing解决锁不安全问题"></p>
<p>client1 申请锁同时拿到<code>token33</code>，然后它进入长时间的停顿锁也过期了。client2 得到锁和<code>token34</code>写入数据，紧接着 client1 活过来之后尝试写入数据，自身<code>token33</code>比<code>34</code>小因此写入操作被拒绝。注意这需要存储层来检查<code>token</code>，但这并不难实现。如果使用<code>Zookeeper</code>作为<code>lock service</code>的话那么可以使用<code>zxid</code>作为递增数字。 但是<strong>对于 Redlock ，没什么生成<code>fencing token</code>的方式，并且怎么修改 Redlock 算法使其能产生<code>fencing toke</code>并不那么显而易见。因为产生<code>token</code>需要单调递增，除非在单节点<code>Redis</code>上完成但是这又没有高可靠性</strong>，需要引进一致性协议来让 Redlock 产生可靠的<code>fencing token</code>。</p>
<h4 id="使用时间来解决一致性"><a href="#使用时间来解决一致性" class="headerlink" title="使用时间来解决一致性"></a>使用时间来解决一致性</h4><p>学术界有个说法，算法对时间不做假设：因为进程可能pause一段时间、数据包可能因为网络延迟延后到达、时钟可能根本就是错的。而可靠的算法依旧要在上述假设下做正确的事情。</p>
<p>同样Redlock算法也是假设所有 Redis 节点都能对同一个 Key 在其过期前持有差不多的时间、跟过期时间相比网络延迟很小、跟过期时间相比进程 pause 很短。</p>
<h4 id="Redlock不可靠的例子"><a href="#Redlock不可靠的例子" class="headerlink" title="Redlock不可靠的例子"></a>Redlock不可靠的例子</h4><p>由于<strong>时间问题</strong>：</p>
<ol>
<li><code>client1</code>从ABC三个节点处申请到锁，DE由于网络原因请求没有到达</li>
<li>C节点的时钟往前推了（或者C崩溃了）导致lock过期</li>
<li><code>client2</code>在CDE出获得了锁，AB由于网络原因请求未到达</li>
<li>此时<code>client1</code>和<code>client2</code>都获得了锁</li>
</ol>
<p>由于<strong>进程pause而不是时钟不可靠发生的问题</strong>：</p>
<ol>
<li><code>client1</code>从ABCDE处获得了锁</li>
<li>当获得锁的<code>response</code>还没到达<code>client1</code>时<code>client1</code>进入GC停顿</li>
<li>停顿期间锁已经过期了</li>
<li><code>client2</code>在ABCDE处获得了锁</li>
<li><code>client1</code>GC完成收到了锁的<code>response</code>，此时两个<code>client</code>又拿到了同一把锁</li>
</ol>
<p>这些例子说明了，仅有在假设了一个同步性系统模型的基础上，Redlock 才能正常工作，也就是系统能满足以下属性：</p>
<ul>
<li>网络延时边界，即假设数据包一定能在某个最大延时之内到达</li>
<li>进程停顿边界，即进程停顿一定在某个最大时间之内</li>
<li>时钟错误边界，即不会从一个坏的 NTP 服务器处取得时间</li>
</ul>
<blockquote>
<p> Redlock 不是一个好的选择，对于需求性能的分布式锁应用它太重了且成本高；对于需求正确性的应用来说它不够安全。因为它对高危的时钟或者说其他上述列举的情况进行了不可靠的假设，如果应用只需要高性能的分布式锁不要求多高的正确性，那么单节点 Redis 够了；如果应用想要保住正确性，那么不建议 Redlock，建议使用一个合适的一致性协调系统，例如<code>Zookeeper</code>，且保证存在<code>fencing token</code>。</p>
</blockquote>
<h1 id="15-Redis底层实现-用到了哪些数据结构"><a href="#15-Redis底层实现-用到了哪些数据结构" class="headerlink" title="15. Redis底层实现/用到了哪些数据结构"></a>15. Redis底层实现/用到了哪些数据结构</h1><h2 id="字典（也叫哈希）"><a href="#字典（也叫哈希）" class="headerlink" title="字典（也叫哈希）"></a>字典（也叫哈希）</h2><p>Redis 使用的是<code>key-value</code>的存储形式</p>
<p><code>dictht</code>是一个散列表结构，使用拉链法解决哈希冲突</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictht</span> &#123;</span></span><br><span class="line">    dictEntry **table;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> <span class="built_in">size</span>;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> sizemask;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> used;</span><br><span class="line">&#125; dictht;</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> &#123;</span></span><br><span class="line">    <span class="keyword">void</span> *key;</span><br><span class="line">    <span class="keyword">union</span> &#123;</span><br><span class="line">        <span class="keyword">void</span> *val;</span><br><span class="line">        <span class="keyword">uint64_t</span> u64;</span><br><span class="line">        <span class="keyword">ini64_t</span> s64;</span><br><span class="line">        <span class="keyword">double</span> d;</span><br><span class="line">    &#125; v;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125; dictEntry;</span><br></pre></td></tr></table></figure>

<p>Redis的字典<code>dict</code>中包含两个哈希表<code>dictht</code>,这是为了方便进行<code>rehash</code>操作。在扩容时，将其中一个<code>dictht</code>上的键值对<code>rehash</code>到另一个<code>dictht</code>上面，完成之后释放空间并交换两个<code>dictht</code>角色</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dict</span> &#123;</span></span><br><span class="line">    dictType *type;</span><br><span class="line">    <span class="keyword">void</span> *privdata;</span><br><span class="line">    dictht ht[<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">long</span> rehashidx;</span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> iterators;</span><br><span class="line">&#125; dict;</span><br></pre></td></tr></table></figure>

<p><code>rehash</code>操作不是一次性完成的，而是采用渐进式，这是为了避免一次性执行过多的<code>rehash</code>操作给服务器造成过大的负担。</p>
<p>渐进式<code>rehash</code>通过记录<code>dict</code>的<code>rehashidx</code>完成，它从0开始，然后每执行一次<code>rehahsh</code>都会递增。例如在一次<code>rehash</code>中，要把<code>dict[0]</code> rehash 到 <code>dict[1]</code>，这一次会把<code>dict[0]</code>上<code>table[rehashidx]</code>的键值对<code>rehash</code>到<code>dict[1]</code>上，<code>dict[0]</code>的<code>table[rehashidx]</code>指向null，并令<code>rehashidx++</code>。</p>
<p>在<code>rehash</code>期间，每次对字典执行添加、删除、查找或者更新操作时，都会执行一次渐进式<code>rehash</code>。</p>
<p>采用渐进式<code>rehash</code>会导致字典中的数据分散在两个<code>dictht</code>上，因此对字典的查找操作也需要到对应的<code>dictht</code>去执行。</p>
<h2 id="跳跃表"><a href="#跳跃表" class="headerlink" title="跳跃表"></a>跳跃表</h2><p>是有序集合的底层实现之一。</p>
<p>与红黑树相比，跳跃表有以下优点：</p>
<ul>
<li>插入速度非常快速，因为不需要进行旋转等操作来维护平衡性</li>
<li>更容易实现</li>
<li>支持无锁操作</li>
</ul>
<h1 id="16-主从复制"><a href="#16-主从复制" class="headerlink" title="16. 主从复制"></a>16. 主从复制</h1><p>建立复制的方法有三种：</p>
<ol>
<li>在配置文件中加入<code>slaveof {masterHost} {masterPort}</code>,随Redis启动生效</li>
<li>在<code>redis-server</code>启动命令后加入<code>--slaveof {masterHost} {masterPort}</code>生效</li>
<li>直接使用命令：<code>slaveof {masterHost} {masterPort}</code>生效</li>
</ol>
<blockquote>
<p><strong>slaveof</strong>命令指定主节点，并将当前节点设置为从节点，建立成功后，从节点会复制主节点的数据。</p>
</blockquote>
<p>复制过程：</p>
<ol>
<li><strong>保存主节点信息</strong>：执行<code>slaveof</code>后从节点只保存主节点的地址信息便直接返回，还未建立复制的完整流程</li>
<li><strong>主从建立socket连接</strong>:从节点内部通过每秒运行的定时任务维护复制的相关逻辑，当定时任务发现存在新的主节点后，会尝试与该节点建立网络连接（通过建立socket套接字，接受主节点发送的复制命令）。如果从节点无法建立连接，定时任务会无限重试直到连接成功或者执行<code>slaveof no one</code></li>
<li><strong>发送<code>ping</code>命令</strong>:连接建立成功后，从节点发送ping命令请求首次通信，检测主从之间网络套接字是否可用，同时检测主节点当前是否可接受处理命令。如果发送<code>ping</code>命令后，从节点没有收到主节点的pong回复或者超时，比如网络超时或者主节点正在阻塞无法响应命令，从节点会断开复制连接，下次定时任务会发起重连</li>
<li><strong>权限验证</strong>：如果主节点设置了<code>requirepass</code>参数，则需要密码验证，从节点必须配置<code>masterauth</code>参数保证与主节点相同的密码才能通过验证；如果验证失败复制将终止，从节点重新发起复制流程。</li>
<li><strong>同步数据集</strong>:主从复制连接正常通信后，对于首次建立复制的场景，主节点会把持有的数据全部发送给从节点，这部分操作是耗时最长的步骤。Redis在2.8版本以后采用新复制命令<code>psync</code>进行数据同步，原来的<code>sync</code>命令依然支持，保证新旧版本的兼容性。新版同步划分两种情况：全量同步和部分同步。</li>
<li><strong>命令持续复制</strong>：当主节点把当前的数据同步给从节点后，便完成了复制的建立流程。接下来主节点会持续地把写命令发送给从节点，保证主从数据一致性。<blockquote>
<p>写命令的发送过程是异步完成，也就是说主节点自身处理完写命令后直接返回给客户端，并不等待从节点复制完成。这就会造成从节点的数据相对主节点存在延迟，具体延迟多少字节，可以通过在主节点执行<code>info replication</code>命令查看。</p>
</blockquote>
</li>
</ol>
<h2 id="主从复制下数据同步方法"><a href="#主从复制下数据同步方法" class="headerlink" title="主从复制下数据同步方法"></a>主从复制下数据同步方法</h2><p>2.8以后Redis使用 psync 命令完成主从数据复制，数据同步过程分为全量复制和部分复制</p>
<ul>
<li>全量复制：一般用于初次复制场景，Redis早期支持的复制功能只有全量复制，它会把主节点全部数据一次性发送给从节点，当数据量较大时，会对主从节点和网络造成很大的开销。</li>
<li>部分复制：用于处理在主从复制中因网络闪断等原因造成的数据丢失场景，当从节点再次连上主节点后，如果条件允许，主节点会补发丢失数据给从节点。因为补发的数据远远小于全量数据，可以有效避免全量复制的过高开销。<br>psync命令运行需要一下组件：</li>
</ul>
<ol>
<li>主从节点各自复制偏移量</li>
<li>主节点复制积压缓冲区</li>
<li>主节点运行id</li>
</ol>
<p>部分复制流程如下：</p>
<ol>
<li>当主从节点之间网络出现中断时，如果超过 repl-timeout 时间，主节点会认为从节点故障并中断复制连接。</li>
<li>主从连接中断期间主节点依然响应命令，但因复制连接中断命令无法发送给从节点，不过主节点内部存在的复制积压缓冲区，依然可以保存最近一段时间的写命令数据，默认最大缓存1MB。</li>
<li>当主从节点网络恢复后，从节点会再次连上主节点.</li>
<li>当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行ID。因此会把它们当作psync 参数发送给主节点，要求进行部分复制操作。</li>
<li>主节点接到 psync 命令后首先核对参数 runId 是否与自身一致，如果一致，说明之前复制的是当前主节点；之后根据参数 offset 在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送 +CONTINUE 响应，表示可以进行部分复制。</li>
<li>主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。</li>
</ol>
<h1 id="17-Redis-哨兵模式"><a href="#17-Redis-哨兵模式" class="headerlink" title="17. Redis 哨兵模式"></a>17. Redis 哨兵模式</h1><p>Redis 哨兵（Sentinel）是Redis提供的一种高可用实现方案，Redis在主从复制下，一旦主节点出现问题，需要人工干预，手动将一个从节点更新为主节点（slaveof no one），同时还要通知应用方新的主节点，让其他从节点去复制新的从节点。这种方式存在弊端大，Redis Sentinel高可用方案就是为了解决这种问题。</p>
<p>Redis Sentinel 是一个分布式架构，其中包含若干个Sentinel节点和Redis数据节点，每个Sentinel节点会对数据节点和其余Sentinel节点进行监控，当它发现节点不可达时，会对节点做下线标识。如果被标识的是主节点，它还会和其他Sentinel节点进行“协商”，当大多数Sentinel节点都认为主节点不可达时，它们会选举出一个Sentinel节点来完成自动故障转移的工作，同时会将这个变化实时通知给Redis应用方。</p>
<h2 id="部署方式"><a href="#部署方式" class="headerlink" title="部署方式"></a>部署方式</h2><ul>
<li>首先部署主节点和从节点</li>
<li>部署sentinel节点<br>在Redis安装目录下有一个 sentinel.conf 的文件，是默认的 sentinel 节点配置文件，对其进行复制和修改</li>
<li>启动Sentinel节点<blockquote>
<p>Sentinel节点默认的端口是26379</p>
</blockquote>
</li>
</ul>
<p>启动节点的方式有两种：</p>
<ol>
<li>使用redis-sentinel命令<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-sentinel sentinel配置文件.conf</span><br></pre></td></tr></table></figure></li>
<li>使用redis-server命令加上 <code>--sentinel</code> 参数<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-server sentinel配置文件.conf —sentinel</span><br></pre></td></tr></table></figure>
<blockquote>
<p>每个sentinel节点会对主节点和所有从节点进行监控，同时Sentinel节点之间也会相互监控</p>
</blockquote>
</li>
</ol>
<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><h3 id="三个定时任务"><a href="#三个定时任务" class="headerlink" title="三个定时任务"></a>三个定时任务</h3><p>Redis Sentinel通过三个定时监控任务完成对每个节点发现和监控：</p>
<ol>
<li>每隔10秒，每个Sentinel节点会向主节点和从节点发送info命令获取最新的拓扑结构，Sentinel节点可以通过info replication的结果进行解析找到相应的从节点。<blockquote>
<p><strong>作用</strong>：通过向主节点执行 info 命令，获取从节点的信息，这也是为什么 Sentinel 节点不需要显式配置监控从节点<br>当有新的从节点加入时都可以立刻感知出来。<br>节点不可达或者故障转移后，可以通过 info 命令实时更新节点拓扑信息。</p>
</blockquote>
</li>
<li>每隔2秒，每个Sentinel会向Redis数据节点的 <code>__sentinel__:hello</code> 频道发送该 Sentinel 节点的信息，同时每个 Sentinel 节点也会订阅该频道，来了解其他 Sentinel 节点以及他们对主节点的判断<blockquote>
<p><strong>作用</strong>：发现新的Sentinel节点：通过订阅主节点的 <code>__sentinel__：hello</code> 了解其他的Sentinel节点信息，如果是新加入的 Sentinel 节点，将该 Sentinel 节点信息保存起来，并与该 Sentinel 节点创建连接<br>Sentinel 节点之间交换主节点的状态，作为后面客观下线以及领导者选举的依据。</p>
</blockquote>
</li>
<li>每隔1秒，每个Sentinel节点会向主节点、从节点、其余Sentinel节点发送一条ping命令做一次心跳检测，来确认这些节点当前是否可达。<blockquote>
<p><strong>作用</strong>：通过对上面的定时任务，Sentinel 节点对主节点、从节点，其余 Sentinel 节点都建立起连接，实现对每个节点的监控，这个定时任务是节点失败判定的重要依据。</p>
</blockquote>
</li>
</ol>
<h3 id="主观下线和客观下线"><a href="#主观下线和客观下线" class="headerlink" title="主观下线和客观下线"></a>主观下线和客观下线</h3><p>每个 Sentinel 节点每隔1秒对主节点、从节点、其他Sentinel节点发送ping命令做心脏检测，当这些节点超过 down-after-milliseconds 没有进行有效恢复时，Seintinel 节点会对该节点做失败判定，这个行为称为<strong>主观下线</strong>。</p>
<p>当 Sentinel 主观下线的节点是主节点时，该 Sentinel 节点会通过 <code>sentinel is-master-down-by-addr</code> 命令向其他 Sentinel 节点询问对主节点的判断。当超过 quorum 个数 Sentinel 节点认为主节点确实有问题，这时就会做出<strong>客观下线</strong>的决定</p>
<h3 id="主节点选取"><a href="#主节点选取" class="headerlink" title="主节点选取"></a>主节点选取</h3><ol>
<li>每个在线的Sentinel节点都有资格成为领导者，当它确认主节点主观下线时候，会向其他Sentinel节点发送 <code>sentinel is-master-down-by-addr</code> 命令， 要求将自己设置为领导者。</li>
<li>收到命令的Sentinel节点，如果没有同意过其他 Sentinel 节点的 <code>sentinel is-master-down-by-addr</code> 命令，将同意该请求，否则拒绝。</li>
<li>如果该 Sentinel 节点发现自己的票数已经大于等于 <code>max（quorum， num（sentinels）/2+1）</code>，那么它将成为领导者。 </li>
<li>如果此过程没有选举出领导者，将进入下一次选举。</li>
</ol>
<h1 id="18-Sorted-Set（即-ZSet-实现原理）"><a href="#18-Sorted-Set（即-ZSet-实现原理）" class="headerlink" title="18. Sorted Set（即 ZSet 实现原理）"></a>18. Sorted Set（即 ZSet 实现原理）</h1><p>ZSet 内部编码实现：</p>
<ul>
<li><code>ziplist</code>(压缩列表)：当哈希类型元素个数小于zset-max-ziplist-entries配置（默认128个），同时所有值小于zset-max-ziplist-value配置（默认64）时，使用ziplist作为内部实现，ziplist使用更加紧凑的结构实现多个元素的连续存储，在节省内存方面更加优秀。</li>
<li><code>skiplist</code>(跳表)：当ziplist条件不满足时，有序集合会使用skiplist作为内部实现，因为此时ziplist的读写效率会下降</li>
</ul>
<h2 id="ZipList"><a href="#ZipList" class="headerlink" title="ZipList"></a>ZipList</h2><p>ziplist 编码的 Zset 使用紧挨在一起的压缩列表节点来保存，第一个节点保存 member，第二个保存 score。ziplist 内的集合元素按 score 从小到大排序，其实质是一个双向链表。虽然元素是按 score 有序排序的， 但对 ziplist 的节点指针只能线性地移动，所以在 <code>REDIS_ENCODING_ZIPLIST</code> 编码的 Zset 中， 查找某个给定元素的复杂度为 O(N)。</p>
<p><img src="http://qiniu.xiaoming.net.cn/ziplist%E7%BB%93%E6%9E%84%E5%9B%BE.png" alt="ziplist结构图"></p>
<h2 id="Skiplist"><a href="#Skiplist" class="headerlink" title="Skiplist"></a>Skiplist</h2><p>skiplist 编码的 Zset 底层为一个被称为 zset 的结构体，这个结构体中<strong>包含一个字典和一个跳跃表</strong>。跳跃表按 score 从小到大保存所有集合元素，查找时间复杂度为平均 O(logN)，最坏 O(N) 。字典则保存着从 member 到 score 的映射，这样就可以用 O(1) 的复杂度来查找 member 对应的 score 值。虽然同时使用两种结构，但它们会通过指针来共享相同元素的 member 和 score，因此不会浪费额外的内存。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* zset结构体 */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zset</span> &#123;</span></span><br><span class="line">    <span class="comment">// 字典，维护元素值和分值的映射关系</span></span><br><span class="line">    dict *dict;</span><br><span class="line">    <span class="comment">// 按分值对元素值排序序，支持O(logN)数量级的查找操作</span></span><br><span class="line">    zskiplist *zsl;</span><br><span class="line">&#125; zset;</span><br></pre></td></tr></table></figure>

<p><img src="http://qiniu.xiaoming.net.cn/ZSet%E4%B8%ADskiplist%E7%BB%93%E6%9E%84.png" alt="ZSet中skiplist结构"></p>
<h3 id="跳表数据结构"><a href="#跳表数据结构" class="headerlink" title="跳表数据结构"></a>跳表数据结构</h3><p>跳表查找时间复杂度为平均 O(logN)，最差 O(N)，在大部分情况下效率可与平衡树相媲美，但实现比平衡树简单的多，跳表是一种典型的以空间换时间的数据结构。</p>
<p>跳表具有以下几个特点：</p>
<ul>
<li>由许多层结构组成。</li>
<li>每一层都是一个有序的链表。</li>
<li>最底层 (Level 1) 的链表包含所有元素。</li>
<li>如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。</li>
<li>每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。</li>
</ul>
<p>跳表的查找会从顶层链表的头部元素开始，然后遍历该链表，直到找到元素大于或等于目标元素的节点，如果当前元素正好等于目标，那么就直接返回它。如果当前元素小于目标元素，那么就垂直下降到下一层继续搜索，如果当前元素大于目标或到达链表尾部，则移动到前一个节点的位置，然后垂直下降到下一层。正因为 Skiplist 的搜索过程会不断地从一层跳跃到下一层的，所以被称为跳跃表。</p>
<p><img src="https://camo.githubusercontent.com/11e7cbe718a70a81c42c37a13a257f91ef48dfd7/687474703a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f31382d31322d392f39333636363231372e6a7067" alt="跳跃表结构"></p>
<p><img src="http://qiniu.xiaoming.net.cn/%E8%B7%B3%E8%A1%A8%E7%BB%93%E6%9E%842.png" alt="跳表结构2"></p>
<p>跳表是一个“概率型”的数据结构，指的就是跳表在插入操作时，元素的插入层数完全是随机指定的。实际上该决定插入层数的随机函数对跳表的查找性能有着很大影响，这并不是一个普通的服从均匀分布的随机数，它的计算过程如下：</p>
<ol>
<li>指定一个节点最大的层数 MaxLevel，指定一个概率 p， 层数 lvl 默认为 1 。</li>
<li>生成一个 0~1 的随机数 r，若 r &lt; p，且 lvl &lt; MaxLevel ，则执行 lvl++。</li>
<li>重复第 2 步，直至生成的 r &gt; p 为止，此时的 lvl 就是要插入的层数。</li>
</ol>
<h3 id="Skiplist-与平衡树、哈希表的比较"><a href="#Skiplist-与平衡树、哈希表的比较" class="headerlink" title="Skiplist 与平衡树、哈希表的比较"></a>Skiplist 与平衡树、哈希表的比较</h3><ul>
<li>Skiplist 和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个 key 的查找，不适宜做范围查找。</li>
<li>在做范围查找的时候，平衡树比 Skiplist 操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。</li>
<li>平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而 Skiplist 的插入和删除只需要修改相邻节点的指针，操作简单又快速。</li>
<li>从内存占用上来说，Skiplist 比平衡树更灵活一些。一般来说，平衡树每个节点包含 2 个指针（分别指向左右子树），而 Skiplist 每个节点包含的指针数目平均为1/(1−p)，具体取决于参数 p 的大小。如果像 Redis 里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。</li>
<li>查找单个 key，Skiplist 和平衡树的时间复杂度都为 O(logN)；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近 O(1)，性能更高一些。</li>
<li>从算法实现难度上来比较，Skiplist 比平衡树要简单得多。</li>
</ul>
<h3 id="Redis-中-Skiplist-的实现"><a href="#Redis-中-Skiplist-的实现" class="headerlink" title="Redis 中 Skiplist 的实现"></a>Redis 中 Skiplist 的实现</h3><p>在 Redis 的 skiplist 实现中，p=1/4 ，MaxLevel=32。</p>
<p>Redis中的 Skiplist 与经典 Skiplist 相比，有如下不同：</p>
<ul>
<li>分数(score)允许重复，即 Skiplist 的 key 允许重复，经典 Skiplist 中是不允许的。</li>
<li>在比较时，不仅比较分数（相当于 Skiplist 的 key），还比较数据本身。在 Redis 的 Skiplist 实现中，数据本身的内容唯一标识这份数据，而不是由 key 来唯一标识。另外，当多个元素分数相同的时候，还需要根据数据内容来进字典排序。</li>
<li>第 1 层链表不是一个单向链表，而是一个双向链表。这是为了方便以倒序方式获取一个范围内的元素。</li>
</ul>
<h3 id="Redis-Zset-采用跳表而不是平衡树的原因"><a href="#Redis-Zset-采用跳表而不是平衡树的原因" class="headerlink" title="Redis Zset 采用跳表而不是平衡树的原因"></a>Redis Zset 采用跳表而不是平衡树的原因</h3><ol>
<li><p>虽然是空间换时间，但也不是非常耗费内存，实际上取决于生成层数函数里的概率 p，取决得当的话其实和平衡树差不多。</p>
</li>
<li><p>因为有序集合经常会进行 ZRANGE 或 ZREVRANGE 这样的范围查找操作，跳表里面的双向链表可以十分方便地进行这类操作。</p>
</li>
<li><p>实现简单，ZRANK 操作还能达到 O(logN) 的时间复杂度。</p>
</li>
</ol>
<h1 id="19-Redis-为什么那么快？"><a href="#19-Redis-为什么那么快？" class="headerlink" title="19. Redis 为什么那么快？"></a>19. Redis 为什么那么快？</h1><p>Redis 快的原因主要有：</p>
<ul>
<li>纯内存操作：是将数据储存在内存里，结构类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)。它的绝大部分请求是纯粹的内存操作，内存响应大约100纳秒，所以他读写数据的时候都不会受到硬盘 I/O 速度的限制，所以速度极快。</li>
<li>单线程：采用单线程，保证了每个操作的原子性，也减少了线程的上下文切换和竞争，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作。</li>
<li>使用多路I/O复用模型，非阻塞IO。（这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求，减少网络 IO 的时间消耗）</li>
<li>高效的数据结构：5种数据结构都有自己的应用场景</li>
<li>合理的数据编码：根据具体使用情况使用不一样的编码（字典渐进式Rehash，跳跃表）</li>
<li>其他方面的优化：定期删除+惰性删除等</li>
</ul>
<h1 id="20-Redis-集群原理"><a href="#20-Redis-集群原理" class="headerlink" title="20. Redis 集群原理"></a>20. Redis 集群原理</h1><h2 id="集群数据分区"><a href="#集群数据分区" class="headerlink" title="集群数据分区"></a>集群数据分区</h2><p>Redis Cluster 采用虚拟槽分区，所有的键根据哈希函数映射到 <code>0~16383</code> 整数槽内，计算公式：<code>slot=CRC16（key）&amp; 16383</code>。每一个节点负责维护一部分槽以及槽所映射的键值数据。</p>
<p><img src="https://github.com/xiao-ming9/xiao-ming9.github.io/blob/master/images/redis%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA.png?raw=true" alt="Redis数据分区"></p>
<p>Redis虚拟槽分区的特点：</p>
<ul>
<li>解耦数据和节点之间的关系，简化了节点扩容和收缩难度。</li>
<li>节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据。</li>
<li>支持节点、槽、键之间的映射查询，用于数据路由、在线伸缩等场景。</li>
</ul>
<p>可以使用 <code>redis-cli --cluster</code> 搭建集群</p>
<h2 id="节点通信"><a href="#节点通信" class="headerlink" title="节点通信"></a>节点通信</h2><p>通信流程：在分布式存储中需要提供维护节点元数据信息的机制，所谓元数据是指：节点负责哪些数据，是否出现故障等状态信息。常见的元数据维护方式分为：集中式和 P2P 方式。Redis集群采用 P2P 的 Gossip（流言）协议，Gossip 协议工作原理就是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息。</p>
<p>通信过程：</p>
<ul>
<li>集群中的每个节点都会单独开辟一个 TCP 通道，用于节点之间彼此通信，通信端口号在基础端口上加10000。</li>
<li>每个节点在固定周期内通过特定规则选择几个节点发送 ping 消息。</li>
<li>接收到 ping 消息的节点用 pong 消息作为响应。</li>
</ul>
<h3 id="Gossip消息"><a href="#Gossip消息" class="headerlink" title="Gossip消息"></a>Gossip消息</h3><p>Gossip protocol 也叫 Epidemic Protocol （流行病协议），实际上它还有很多别名，比如：“流言算法”、“疫情传播算法”等。</p>
<p>Gossip 过程是由种子节点发起，当一个种子节点有状态需要更新到网络中的其他节点时，它会随机的选择周围几个节点散播消息，收到消息的节点也会重复该过程，直至最终网络中所有的节点都收到了消息。这个过程可能需要一定的时间，由于不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，因此它是一个最终一致性协议。</p>
<p>Gossip 协议的主要职责就是信息交换。信息交换的载体就是节点彼此发送的 Gossip 消息。常用的 Gossip消息可分为：ping 消息、pong 消息、meet 消息、fail 消息。</p>
<ul>
<li>meet 消息：用于通知新节点加入。消息发送者通知接收者加入到当前集群，meet 消息通信正常完成后，接收节点会加入到集群中并进行周期性的 ping、pong 消息交换。</li>
<li>ping 消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点发送 ping 消息，用于检测节点是否在线和交换彼此状态信息。ping 消息发送封装了自身节点和部分其他节点的状态数据。</li>
<li>pong 消息：当接收到 ping、meet 消息时，作为响应消息回复给发送方确认消息正常通信。pong 消息内部封装了自身状态数据。节点也可以向集群内广播自身的 pong 消息来通知整个集群对自身状态进行更新。</li>
<li>fail 消息：当节点判定集群内另一个节点下线时，会向集群内广播一个 fail 消息，其他节点接收到 fail 消息之后把对应节点更新为下线状态。</li>
</ul>
<p>所有的消息格式划分为：消息头和消息体。</p>
<h4 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h4><ul>
<li>扩展性：网络可以允许节点的任意增加和减少，新增加的节点的状态最终会与其他节点一致。</li>
<li>容错：网络中任何节点的宕机和重启都不会影响 Gossip 消息的传播，Gossip 协议具有天然的分布式系统容错特性。</li>
<li>去中心化：Gossip 协议不要求任何中心节点，所有节点都可以是对等的，任何一个节点无需知道整个网络状况，只要网络是连通的，任意一个节点就可以把消息散播到全网。</li>
<li>一致性收敛：Gossip 协议中的消息会以一传十、十传百一样的指数级速度在网络中快速传播，因此系统状态的不一致可以在很快的时间内收敛到一致。消息传播速度达到了 logN。</li>
<li>简单：Gossip 协议的过程极其简单，实现起来几乎没有太多复杂性。</li>
</ul>
<h4 id="Gossip-的缺陷"><a href="#Gossip-的缺陷" class="headerlink" title="Gossip 的缺陷"></a>Gossip 的缺陷</h4><p>分布式网络中，没有一种完美的解决方案，Gossip 协议跟其他协议一样，也有一些不可避免的缺陷，主要是两个：</p>
<ul>
<li>消息的延迟：</li>
</ul>
<p>由于 Gossip 协议中，节点只会随机向少数几个节点发送消息，消息最终是通过多个轮次的散播而到达全网的，因此使用 Gossip 协议会造成不可避免的消息延迟。不适合用在对实时性要求较高的场景下。</p>
<ul>
<li>消息冗余：</li>
</ul>
<p>Gossip 协议规定，节点会定期随机选择周围节点发送消息，而收到消息的节点也会重复该步骤，因此就不可避免的存在消息重复发送给同一节点的情况，造成了消息的冗余，同时也增加了收到消息的节点的处理压力。而且，由于是定期发送而且不反馈，因此，即使节点收到了消息，还是会反复收到重复消息，加重了消息的冗余。</p>
<h2 id="节点选择"><a href="#节点选择" class="headerlink" title="节点选择"></a>节点选择</h2><p>Redis集群内节点通信采用固定频率（定时任务每秒执行10次）。</p>
<p><img src="https://github.com/xiao-ming9/xiao-ming9.github.io/blob/master/images/redis%E9%9B%86%E7%BE%A4%E5%86%85%E8%8A%82%E7%82%B9%E9%80%9A%E4%BF%A1.png?raw=true" alt="Redis 集群节点选择"></p>
<p>由上图可以看出：消息交换的成本主要体现在单位时间选择发送消息的节点数量和每个消息携带的数据量</p>
<h3 id="选择发送消息的节点数量"><a href="#选择发送消息的节点数量" class="headerlink" title="选择发送消息的节点数量"></a>选择发送消息的节点数量</h3><p>集群内每个节点维护定时任务默认每秒执行10次，每秒会随机选取5个节点找出最久没有通信的节点发送ping消息，用于保证 Gossip 信息交换的随机性。每 100 毫秒都会扫描本地节点列表，如果发现节点最近一次接受 pong 消息的时间大于 <code>cluster_node_timeout/2</code>，则立刻发送 ping 消息，防止该节点信息太长时间未更新。根据以上规则得出每个节点每秒需要发送 ping 消息的数量 = <code>1+10*num（node.pong_received&gt;cluster_node_timeout/2)</code>。</p>
<h3 id="消息数据量"><a href="#消息数据量" class="headerlink" title="消息数据量"></a>消息数据量</h3><p>每个 ping 消息的数据量体现在消息头和消息体中，其中消息头主要占用空间的字段是 <code>myslots[CLUSTER_SLOTS/8]</code>，占用 2KB，这块空间占用相对固定。消息体会携带一定数量的其他节点信息用于信息交换。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def get_wanted():</span><br><span class="line">	int total_size = size(cluster.nodes) </span><br><span class="line">	# 默认包含节点总量的1/10 594 </span><br><span class="line">	int wanted = floor(total_size/10); </span><br><span class="line">	if wanted &lt; 3: </span><br><span class="line">		# 至少携带3个其他节点信息 </span><br><span class="line">		wanted = 3; </span><br><span class="line">	if wanted &gt; total_size -2 : </span><br><span class="line">		# 最多包含total_size - 2个 </span><br><span class="line">		wanted = total_size - 2; </span><br><span class="line">	return wanted;</span><br></pre></td></tr></table></figure>

<h1 id="21-Redis-集群如何进行故障迁移"><a href="#21-Redis-集群如何进行故障迁移" class="headerlink" title="21. Redis 集群如何进行故障迁移"></a>21. Redis 集群如何进行故障迁移</h1><p>当集群内少量节点出现故障时通过自动故障转移保证集群可以正常对外提供服务</p>
<h2 id="故障发现"><a href="#故障发现" class="headerlink" title="故障发现"></a>故障发现</h2><p>Redis 集群内节点通过 ping/pong 消息实现节点通信，消息不但可以传播节点槽信息，还可以传播其他状态如：主从状态、节点故障等。因此故障发现也是通过消息传播机制实现的，主要环节包括：主观下线（pfail）和客观下线（fail）</p>
<ul>
<li>主观下线：指某个节点认为另一个节点不可用，即下线状态，这个状态并不是最终的故障判定，只能代表一个节点的意见，可能存在误判情况。</li>
<li>客观下线：指标记一个节点真正的下线，集群内多个节点都认为该节点不可用，从而达成共识的结果。如果是持有槽的主节点故障，需要为该节点进行故障转移。</li>
</ul>
<h3 id="主观下线"><a href="#主观下线" class="headerlink" title="主观下线"></a>主观下线</h3><p>集群中每个节点都会定期向其他节点发送 ping 消息，接收节点回复 pong 消息作为响应。如果在 <code>cluster-node-timeout</code> 时间内通信一直失败，则发送节点会认为接收节点存在故障，把接收节点标记为主观下线（pfail）状态。</p>
<p>具体流程：</p>
<ol>
<li>节点 a 发送 ping 消息给节点 b，如果通信正常将接收到 pong 消息，节点 a 更新最近一次与节点 b 的通信时间。</li>
<li>如果节点 a 与节点 b 通信出现问题则断开连接，下次会进行重连。如果一直通信失败，则节点 a 记录的与节点 b 最后通信时间将无法更新。</li>
<li>节点 a 内的定时任务检测到与节点 b 最后通信时间超过 <code>cluster-node-timeout</code> 时，更新本地对节点 b 的状态为主观下线（pfail）。</li>
</ol>
<h3 id="客观下线"><a href="#客观下线" class="headerlink" title="客观下线"></a>客观下线</h3><p>当某个节点判断另一个节点主观下线后，相应的节点状态会跟随消息在集群内传播。ping/pong 消息的消息体会携带集群 1/10 的其他节点状态数据，当接受节点发现消息体中含有主观下线的节点状态时，会在本地找到故障节点的 <code>ClusterNode</code> 结构，保存到下线报告链表中。结构如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">struct clusterNode &#123; /* 认为是主观下线的clusterNode结构 */ </span><br><span class="line">	list *fail_reports; /* 记录了所有其他节点对该节点的下线报告 */ </span><br><span class="line">	... </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>通过 Gossip 消息传播，集群内节点不断收集到故障节点的下线报告。当半数以上持有槽的主节点都标记某个节点是主观下线时，触发客观下线流程。</p>
<p>集群模式下只有处理槽的主节点才负责读写请求和集群槽等关键信息维护，而从节点只进行主节点数据和状态信息的复制。所以必须是负责槽的主节点参与故障发现决策</p>
<p>客观下线流程：</p>
<ol>
<li>当消息体内含有其他节点的 pfail 状态会判断发送节点的状态，如果发送节点是主节点则对报告的 pfail 状态处理，从节点则忽略。</li>
<li>找到 pfail 对应的节点结构，更新 clusterNode 内部下线报告链表。</li>
<li>根据更新后的下线报告链表告尝试进行客观下线。</li>
</ol>
<h4 id="下线报告链表"><a href="#下线报告链表" class="headerlink" title="下线报告链表"></a>下线报告链表</h4><p>每个 ClusterNode 结构中都会存在一个下线链表结构，保存了其他主节点针对当前节点的下线报告：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">typedef struct clusterNodeFailReport &#123; </span><br><span class="line">	struct clusterNode *node; /* 报告该节点为主观下线的节点 */ </span><br><span class="line">	mstime_t time; /* 最近收到下线报告的时间 */ </span><br><span class="line">&#125; clusterNodeFailReport;</span><br></pre></td></tr></table></figure>

<p>下线报告中保存了报告故障的节点结构和最近收到下线报告的时间，当接收到 fail 状态时，会维护对应节点的下线上报链表。每个下线报告都存在有效期，每次在尝试触发客观下线时，都会检测下线报告是否过期，对于过期的下线报告将被删除。如果在 <code>cluster-node-time*2</code> 的时间内该下线报告没有得到更新则过期并删除.</p>
<h4 id="尝试客观下线"><a href="#尝试客观下线" class="headerlink" title="尝试客观下线"></a>尝试客观下线</h4><p>集群中的节点每次接收到其他节点的 pfail 状态，都会尝试触发客观下线：</p>
<ol>
<li>首先统计有效的下线报告数量，如果小于集群内持有槽的主节点总数的一半则退出。</li>
<li>当下线报告大于槽主节点数量一半时，标记对应故障节点为客观下线状态。</li>
<li>向集群广播一条 fail 消息，通知所有的节点将故障节点标记为客观下线，fail 消息的消息体只包含故障节点的ID。</li>
</ol>
<p>广播 fail 消息有一下两个作用：</p>
<ul>
<li>通知集群内所有的节点标记故障节点为客观下线状态并立即生效</li>
<li>通知故障节点的从节点触发故障转移流程</li>
</ul>
<h2 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h2><p>故障节点变为客观下线后，如果下线节点是持有槽的主节点，则需要在它的从节点中选出一个替换它，从而保证集群的高可用。下线主节点的所有从节点承担故障恢复的义务，当从节点通过内部定时任务发现自身复制的主节点进入客观下线时，将会触发故障恢复流程：</p>
<ul>
<li>资格检查</li>
<li>准备选举时间</li>
<li>发起选举</li>
<li>选举投票</li>
<li>替换主节点</li>
<li>资格检查</li>
</ul>
<h3 id="资格检查"><a href="#资格检查" class="headerlink" title="资格检查"></a>资格检查</h3><p>每个从节点都要检查最后与主节点断线时间，判断是否有资格替换故障的主节点。如果从节点与主节点断线时间超过 <code>cluster-node-time*cluster-slave-validity-factor</code>，则当前从节点不具备故障转移资格。参数<code>cluster-slavevalidity-factor</code>用于从节点的有效因子，默认为10。</p>
<h3 id="准备选举时间"><a href="#准备选举时间" class="headerlink" title="准备选举时间"></a>准备选举时间</h3><p>当从节点符合故障转移资格后，更新触发故障选举的时间，只有到达该时间后才能执行后续流程。故障选举时间相关字段如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">struct clusterState &#123; </span><br><span class="line">	... </span><br><span class="line">	mstime_t failover_auth_time; /* 记录之前或者下次将要执行故障选举时间 */ </span><br><span class="line">	int failover_auth_rank; /* 记录当前从节点排名 */ </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>采用延迟触发机制，主要是通过对多个从节点使用不同的延迟选举时间来支持优先级问题。复制偏移量越大说明从节点延迟越低，那么它应该具有更高的优先级来替换故障主节点。</p>
<p><img src="https://github.com/xiao-ming9/xiao-ming9.github.io/blob/master/images/redis%E9%80%89%E4%B8%BE%E5%BB%B6%E8%BF%9F%E5%87%BA%E5%8F%91%E6%9C%BA%E5%88%B6.png?raw=true" alt="准备选举时间"></p>
<h3 id="发起选举"><a href="#发起选举" class="headerlink" title="发起选举"></a>发起选举</h3><p>当从节点定时任务检测到达故障选举时间（failover_auth_time）到达后，发起选举流程如下：</p>
<h3 id="更新配置纪元："><a href="#更新配置纪元：" class="headerlink" title="更新配置纪元："></a>更新配置纪元：</h3><p>配置纪元是一个只增不减的整数，每个主节点自身维护一个配置纪元（clusterNode.configEpoch）标示当前主节点的版本，所有主节点的配置纪元都不相等，从节点会复制主节点的配置纪元。整个集群又维护一个全局的配置纪元（clusterState.current Epoch），用于记录集群内所有主节点配置纪元的最大版本。执行 cluster info 命令可以查看配置纪元信息。配置纪元会跟随 ping/pong 消息在集群内传播，当发送方与接收方都是主节点且配置纪元相等时代表出现了冲突，nodeId 更大的一方会递增全局配置纪元并赋值给当前节点来区分冲突。</p>
<p>配置纪元的主要作用：</p>
<ul>
<li>标示集群内每个主节点的不同版本和当前集群最大的版本。</li>
<li>每次集群发生重要事件时，这里的重要事件指出现新的主节点（新加入的或者由从节点转换而来），从节点竞争选举。都会递增集群全局的配置纪元并赋值给相关主节点，用于记录这一关键事件。</li>
<li>主节点具有更大的配置纪元代表了更新的集群状态，因此当节点间进行ping/pong消息交换时，如出现slots 等关键信息不一致时，以配置纪元更大的一方为准，防止过时的消息状态污染集群。</li>
<li>从节点每次发起投票时都会自增集群的全局配置纪元，并单独保存在 <code>clusterState.failover_auth_epoch</code> 变量中用于标识本次从节点发起选举的版本。</li>
</ul>
<h3 id="广播选举消息"><a href="#广播选举消息" class="headerlink" title="广播选举消息"></a>广播选举消息</h3><p>在集群内广播选举消息（FAILOVER_AUTH_REQUEST），并记录已发送过消息的状态，保证该从节点在一个配置纪元内只能发起一次选举。消息内容如同 ping 消息只是将 type 类型变为 FAILOVER_AUTH_REQUEST。</p>
<h3 id="选举投票"><a href="#选举投票" class="headerlink" title="选举投票"></a>选举投票</h3><p>只有持有槽的主节点才会处理故障选举消息（FAILOVER_AUTH_REQUEST），因为每个持有槽的节点在一个配置纪元内都有唯一的一张选票，当接到第一个请求投票的从节点消息时回复 FAILOVER_AUTH_ACK 消息作为投票，之后相同配置纪元内其他从节点的选举消息将忽略。</p>
<p>当从节点收集到 <code>N/2 + 1</code> 个持有槽的主节点投票时，从节点可以执行替换主节点操作。</p>
<ul>
<li>投票作废：每个配置纪元代表了一次选举周期，如果在开始投票之后的 <code>cluster-node-timeout * 2</code> 时间内从节点没有获取足够数量的投票，则本次选举作废。从节点对配置纪元自增并发起下一轮投票，直到选举成功为止。</li>
</ul>
<h3 id="替换主节点"><a href="#替换主节点" class="headerlink" title="替换主节点"></a>替换主节点</h3><p>当前从节点取消复制变为主节点。</p>
<p>执行 clusterDelSlot 操作撤销故障主节点负责的槽，并执行 clusterAddSlot 把这些槽委派给自己。<br>向集群广播自己的 pong 消息，通知集群内所有的节点当前从节点变为主节点并接管了故障主节点的槽信息。</p>
<h1 id="22-Redis-集群伸缩（增加节点、删除节点）"><a href="#22-Redis-集群伸缩（增加节点、删除节点）" class="headerlink" title="22. Redis 集群伸缩（增加节点、删除节点）"></a>22. Redis 集群伸缩（增加节点、删除节点）</h1><p>集群的伸缩包括新节点的加入和旧节点退出。</p>
<p>新节点时加入时，我们需要把一部分数据迁移到新节点来达到集群的负载均衡，旧节点退出时，我们需要把其上的数据迁移到其他节点上，确保该节点上的数据能够被正常访问。</p>
<p>我们发现集群伸缩的核心其实是数据的迁移，而在 Redis 集群中，数据是以 slot 为单位的，那么也就是说，Redis 集群的伸缩本质上是 slot 在不同机器节点间的迁移。同时，要实现扩缩容，我们不仅需要解决数据迁移，我们还需要解决数据路由问题。比如 A 节点正在向 B 节点迁移 slot1 的数据，在未完成迁移时，slot1 中的一部分数据存在节点A上，一部分数据存在节点B上。那么以下三种情况下我们该如何路由 slot1 的客户端请求？</p>
<ol>
<li>当除了 A、B 之外的其他节点接收到 slot1 的数据请求时，其他节点该路由给哪个节点？</li>
<li>当节点 A 接收到 slot1 的数据请求时，A 该自己处理还是路由给 B 节点？</li>
<li>当节点 B 接收到 slot1 的数据请求时，B 该自己处理还是路由给A节点？</li>
</ol>
<h2 id="集群扩容"><a href="#集群扩容" class="headerlink" title="集群扩容"></a>集群扩容</h2><p>Redis集群加入新节点主要分为如下几步：</p>
<ol>
<li>准备新节点</li>
<li>加入集群</li>
<li>迁移slot到新节点。</li>
</ol>
<p>即首先启动一个集群模式下的 Redis 节点，然后通过与任意一个集群中的节点握手使得新的节点加入集群，最后再向新的节点分配它负责的 slot 以及向其迁移 slot 对应的数据。由于 Redis 采用 Gossip 协议，所以可以让新节点与任意一个现有集群节点握手，一段时间后整个集群都会知道新节点的加入。</p>
<p>例如我们向该集群中新加入一个节点 6385。由于我们要追求负载均衡，所以加入后四个节点每个节点负责 4096 个slots，但是集群中原来的每个节点都负责 5462 个slots，所以 6379、6380、6381 节点都需要向新的节点 6385 迁移 1366 个slots。需要说明的是，Redis 集群并没有一个自动实现负载均衡的工具，把多少 slots 从哪个节点迁移到哪个节点完全是由用户自己来指定的。</p>
<p><img src="http://qiniu.xiaoming.net.cn/Redis%E9%9B%86%E7%BE%A4%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB.jpg" alt="Redis集群数据迁移"></p>
<h3 id="设置节点迁入迁出状态——解决路由困境"><a href="#设置节点迁入迁出状态——解决路由困境" class="headerlink" title="设置节点迁入迁出状态——解决路由困境"></a>设置节点迁入迁出状态——解决路由困境</h3><p>每个 Redis 集群节点的 clusterState 都会存储整个集群中 slot 和 Redis 节点的对应关系用于路由。当 6379 迁移 slot1 时，会首先标级该槽属于正在迁移的状态 IMGRATING，而同样 6385 也需要标记 slot1 属于正在导入的状态 IMPORTING。从实现上看，就是分别设置 <code>migrating_slots_to</code> 和 <code>importing_slots_from</code> 两个数组的对应 <code>index</code> 的值。迁入迁出的状态设置主要是为了方便数据路由的实现。在未完成迁移之前，集群中的所有节点都会将 slot1 的请求重定向到6379节点。</p>
<p>而当 6379 把 <code>slot1</code> 标记为MIGRATING时，该节点会接收所有关于 <code>slot1</code> 的请求，但只有当请求中的 <code>key</code> 存在于 6379 中时该节点才会处理该请求。否则 6379 会把该请求通过 ASK 重定向到 slot1 的迁移目标节点，即 6385 节点。</p>
<p>而当 6385 把 slot1 标记为 <code>IMPORTING</code> 时，该节点也可以接受关于 slot1 的请求，但前提是该请求中必须包含 <code>ASKING</code> 命令。如果关于 slot1 的请求中没有 <code>ASKING</code> 命令，那么 6385 节点会把该请求通过 <code>MOVED</code> 重定向到 6379 节点。</p>
<p>这样我们就解决了上述的三个问题，即：</p>
<ol>
<li>当除了 A、B 之外的其他节点接收到 slot1 的数据请求时，其他节点该路由给 A 节点</li>
<li>当节点A接收到 slot1 的数据请求时，如果请求的key存在，那么就会处理，不存在就会ASK重定向到B</li>
<li>当节点B接收到 slot1 的数据请求时，如果请求中有 ASKING 命令，那么就会自己处理。如果没有，那么重定向到 A。</li>
</ol>
<p>当迁移 slot1 结束后，slot1 就不再由 6379 负责而是交给 6385 节点负责。但是从其他节点的视角看，slot1 仍然由 6379 节点负责，他们接收到关于 slot1 的键的请求还是会路由到 6379 节点。所以迁移结束之后我们要向集群广播 slot1 由 6385 节点负责的消息，这样每个节点都会更新内部的路由数据，之后就可以正确的把 slot1 的键的请求路由到 6385 节点。需要说明的是，我们可以把上述的更新信息只告诉一个节点，那么随着各个节点信息的交换，一段时间后整个集群的所有节点都会更新路由。但是这样显然更新的延迟会很高，那些还没来得及更新的节点仍然会错误的把 slot1 的请求路由给 6379 节点。所以我们需要向每个节点进行广播消息。</p>
<h2 id="集群收缩"><a href="#集群收缩" class="headerlink" title="集群收缩"></a>集群收缩</h2><p>集群收缩即让其中一些节点安全下线。所谓的安全下线指的是让一个节点下线之前我们需要把其负责的所有 slots 迁移到别的节点，否则该节点下线后其负责的 slots 就没法继续被服务了。节点下线的流程如下图所示：</p>
<p><img src="http://qiniu.xiaoming.net.cn/Redis%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9%E5%AE%89%E5%85%A8%E4%B8%8B%E7%BA%BF.jpg" alt="Redis集群节点安全下线"></p>
<p>在上面的扩容完成后，集群中共有四个节点：6379、6380、6381、6385，我们以下线 6381 为例介绍下线的流程。下线 6381 节点首先需要把其上负责 slots 的数据分别迁移到三个节点上，然后通知所有集群中的节点忘记 6381 节点，最后 6381 节点关闭下线。</p>
<p>Redis 的元数据在每个节点中都有一份，即每个 Redis 节点维护者从它的视角看过去集群中所有其他节点的状态。那么当集群中的所有其他节点接收到 <code>CLUSTER FORGET &lt;NODE ID&gt;</code> 命令时会删除自己保存的 <code>NODE_ID</code> 对应的节点的状态，同时把 <code>NODE_ID</code> 对应的节点加入到黑名单中 60s。把一个节点放入黑名单意味着其他节点不会再去更新自己维护的该节点的信息，也就意味着当我们向集群中的所有节点发送<code>CLUSTER FORGET 6381</code> 后，6381节点 60s 内不能再次加入集群中。至此就完成了集群的缩容。</p>
<h1 id="23-Redis应用场景"><a href="#23-Redis应用场景" class="headerlink" title="23. Redis应用场景"></a>23. Redis应用场景</h1><h2 id="热点数据"><a href="#热点数据" class="headerlink" title="热点数据"></a>热点数据</h2><p>存取数据优先从 Redis 操作，如果不存在再从文件（例如 MySQL）中操作，从文件操作完后将数据存储到 Redis 中并返回。同时有个定时任务后台定时扫描 Redis 的 key，根据业务规则进行淘汰，防止某些只访问一两次的数据一直存在 Redis 中。</p>
<p>例如使用 Zset 数据结构，存储 Key 的访问次数/最后访问时间作为 Score，最后做排序，来淘汰那些最少访问的 Key。</p>
<h2 id="会话维持-Session"><a href="#会话维持-Session" class="headerlink" title="会话维持 Session"></a>会话维持 Session</h2><p>会话维持 Session 场景，即使用 Redis 作为分布式场景下的登录中心存储应用。每次不同的服务在登录的时候，都会去统一的 Redis 去验证 Session 是否正确。但是在微服务场景，一般会考虑 Redis + JWT 做 Oauth2 模块。</p>
<p>其中 Redis 存储 JWT 的相关信息主要是留出口子，方便以后做统一的防刷接口，或者做登录设备限制等。</p>
<h2 id="分布式锁-SETNX"><a href="#分布式锁-SETNX" class="headerlink" title="分布式锁 SETNX"></a>分布式锁 SETNX</h2><p>命令格式：<code>SETNX key value</code>：当且仅当 key 不存在，将 key 的值设为 value。若给定的 key 已经存在，则 SETNX 不做任何动作。</p>
<p>超时时间设置：获取锁的同时，启动守护线程，使用 <code>expire</code> 进行定时更新超时时间。如果该业务机器宕机，守护线程也挂掉，这样也会自动过期。如果该业务不是宕机，而是真的需要这么久的操作时间，那么增加超时时间在业务上也是可以接受的，但是肯定有个最大的阈值。</p>
<p>但是为了增加高可用，需要使用多台 Redis，就增加了复杂性，就可以参考 Redlock：Redlock分布式锁</p>
<h2 id="表缓存"><a href="#表缓存" class="headerlink" title="表缓存"></a>表缓存</h2><p>Redis 缓存表的场景有黑名单、禁言表等。访问频率较高，即读高。根据业务需求，可以使用后台定时任务定时刷新 Redis 的缓存表数据。</p>
<h2 id="消息队列-list"><a href="#消息队列-list" class="headerlink" title="消息队列 list"></a>消息队列 list</h2><p>主要使用了 List 数据结构。</p>
<p>List 支持在头部和尾部操作，因此可以实现简单的消息队列。</p>
<ul>
<li>发消息：在 List 尾部塞入数据。</li>
<li>消费消息：在 List 头部拿出数据。</li>
</ul>
<p>同时可以使用多个 List，来实现多个队列，根据不同的业务消息，塞入不同的 List，来增加吞吐量。</p>
<h2 id="计数器-string"><a href="#计数器-string" class="headerlink" title="计数器 string"></a>计数器 string</h2><p>主要使用了 INCR、DECR、INCRBY、DECRBY 方法。</p>
<p>INCR key：给 key 的 value 值增加一 DECR key：给 key 的 value 值减去一</p>
<h1 id="24-Redis-压力测试"><a href="#24-Redis-压力测试" class="headerlink" title="24. Redis 压力测试"></a>24. Redis 压力测试</h1><p>Redis 自带了一个叫 <code>redis-benchmark</code> 的工具来模拟 N 个客户端同时发出 M 个请求。 （类似于 Apache ab 程序）。你可以使用 <code>redis-benchmark -h</code> 来查看基准参数。</p>
<p>参数:</p>
<table>
<thead>
<tr>
<th>选项</th>
<th>描述</th>
<th>默认值</th>
</tr>
</thead>
<tbody><tr>
<td>-h</td>
<td>指定redis server 主机名</td>
<td>localhost</td>
</tr>
<tr>
<td>-p</td>
<td>指定redis 服务端口</td>
<td>6379</td>
</tr>
<tr>
<td>-s</td>
<td>指定服务器socket</td>
<td></td>
</tr>
<tr>
<td>-c</td>
<td>clients,代表客户端并发连接数</td>
<td>50</td>
</tr>
<tr>
<td>-n</td>
<td>指定请求数</td>
<td>10000</td>
</tr>
<tr>
<td>-d</td>
<td>以字节形式指定SET/GET值的数值大小</td>
<td>2</td>
</tr>
<tr>
<td>-k</td>
<td>1 = keepalive 0 = reconnect</td>
<td>1</td>
</tr>
<tr>
<td>-r</td>
<td>向 redis 中插入更多的键。-r 选项会在键名上加一个12位的后缀，<code>-r 10000</code> 表示只对后四位做随机处理，SET/GET/INCR 使用随机 key, SADD 使用随机值</td>
<td></td>
</tr>
<tr>
<td>-P</td>
<td>通过管道传输 <code>&lt;numreq&gt;</code> 请求</td>
<td>1</td>
</tr>
<tr>
<td>-q</td>
<td>强制退出 redis.仅显示 query per sec 信息</td>
<td></td>
</tr>
<tr>
<td>-csv</td>
<td>以 csv 格式输出</td>
<td></td>
</tr>
<tr>
<td>-l</td>
<td>生成循环 永久执行测试</td>
<td></td>
</tr>
<tr>
<td>-t</td>
<td>对指定命令做基准测试，仅运行以逗号分隔的测试命令列表</td>
<td></td>
</tr>
<tr>
<td>-I</td>
<td>Idle模式,仅打开 N 个 idle 连接并等待</td>
<td></td>
</tr>
</tbody></table>
<p><strong>参考内容</strong></p>
<blockquote>
<p>主要参考以来两篇博客以及相关博客推荐，因找的博客比较多，没注意记录，最后好多忘了在哪2333，如果有侵权，请及时联系我，非常抱歉。<br><a href="https://github.com/Snailclimb/JavaGuide" target="_blank" rel="noopener">https://github.com/Snailclimb/JavaGuide</a><br><a href="https://github.com/CyC2018/CS-Notes" target="_blank" rel="noopener">https://github.com/CyC2018/CS-Notes</a><br><a href="https://marticles.github.io/2019/03/19/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Redis-Zset%E5%8E%9F%E7%90%86/" target="_blank" rel="noopener">深入理解Redis-ZSet原理</a><br><a href="https://www.lagou.com/lgeduarticle/44550.html" target="_blank" rel="noopener">Redis面试篇 – 如何保证缓存与数据库的双写一致性？</a><br><a href="https://segmentfault.com/a/1190000015571891" target="_blank" rel="noopener">redis压力测试</a><br><a href="https://zhuanlan.zhihu.com/p/105569485" target="_blank" rel="noopener">Redis集群(中) —— 集群伸缩</a><br><a href="https://blog.csdn.net/zzm848166546/article/details/80360665" target="_blank" rel="noopener">Redis基础、常用类型介绍、时间复杂度</a>  </p>
</blockquote>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Redis/" rel="tag"># Redis</a>
              <a href="/tags/%E9%9D%A2%E8%AF%95/" rel="tag"># 面试</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/09/30/%E9%9D%A2%E8%AF%95%E5%A4%8D%E4%B9%A0%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E5%BA%93MySQL/" rel="prev" title="数据库MySQL">
      <i class="fa fa-chevron-left"></i> 数据库MySQL
    </a></div>
      <div class="post-nav-item">
    <a href="/2019/10/26/shell%E5%9F%BA%E7%A1%80/" rel="next" title="Shell基础">
      Shell基础 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Redis数据类型"><span class="nav-number">1.</span> <span class="nav-text">1. Redis数据类型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#String"><span class="nav-number">1.1.</span> <span class="nav-text">String</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#各个指令的时间复杂度"><span class="nav-number">1.1.1.</span> <span class="nav-text">各个指令的时间复杂度</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hash"><span class="nav-number">1.2.</span> <span class="nav-text">Hash</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#各个指令的时间复杂度-1"><span class="nav-number">1.2.1.</span> <span class="nav-text">各个指令的时间复杂度</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#List"><span class="nav-number">1.3.</span> <span class="nav-text">List</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#各个指令的时间复杂度-2"><span class="nav-number">1.3.1.</span> <span class="nav-text">各个指令的时间复杂度</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Set"><span class="nav-number">1.4.</span> <span class="nav-text">Set</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#各个指令的时间复杂度-3"><span class="nav-number">1.4.1.</span> <span class="nav-text">各个指令的时间复杂度</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ZSet"><span class="nav-number">1.5.</span> <span class="nav-text">ZSet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#各个指令的时间复杂度-4"><span class="nav-number">1.5.1.</span> <span class="nav-text">各个指令的时间复杂度</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Bitmaps"><span class="nav-number">1.6.</span> <span class="nav-text">Bitmaps</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#常用指令"><span class="nav-number">1.6.1.</span> <span class="nav-text">常用指令</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HyperLogLog"><span class="nav-number">1.7.</span> <span class="nav-text">HyperLogLog</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-为什么要用redis-为什么要用缓存"><span class="nav-number">2.</span> <span class="nav-text">2. 为什么要用redis/为什么要用缓存</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-为什么使用redis而不直接在程序中使用map-guava做缓存？"><span class="nav-number">3.</span> <span class="nav-text">3. 为什么使用redis而不直接在程序中使用map/guava做缓存？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-redi的线程模型"><span class="nav-number">4.</span> <span class="nav-text">4. redi的线程模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-redis和memcached的区别"><span class="nav-number">5.</span> <span class="nav-text">5. redis和memcached的区别</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-redis过期键处理方式"><span class="nav-number">6.</span> <span class="nav-text">6. redis过期键处理方式</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-redis内存淘汰机制（MySQL中有2000w数据，Redis中只存了20w数据，如何保证Redis中的数据都是热点数据？）"><span class="nav-number">7.</span> <span class="nav-text">7. redis内存淘汰机制（MySQL中有2000w数据，Redis中只存了20w数据，如何保证Redis中的数据都是热点数据？）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#8-Redis数据持久化（怎么保证Redis挂掉之后再重启数据不会丢失）"><span class="nav-number">8.</span> <span class="nav-text">8. Redis数据持久化（怎么保证Redis挂掉之后再重启数据不会丢失）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#RDB"><span class="nav-number">8.1.</span> <span class="nav-text">RDB</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#触发机制"><span class="nav-number">8.1.1.</span> <span class="nav-text">触发机制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#手动触发"><span class="nav-number">8.1.1.1.</span> <span class="nav-text">手动触发</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自动触发"><span class="nav-number">8.1.1.2.</span> <span class="nav-text">自动触发</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#流程说明"><span class="nav-number">8.1.2.</span> <span class="nav-text">流程说明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优缺点"><span class="nav-number">8.1.3.</span> <span class="nav-text">优缺点</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#优点"><span class="nav-number">8.1.3.1.</span> <span class="nav-text">优点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#缺点"><span class="nav-number">8.1.3.2.</span> <span class="nav-text">缺点</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AOF"><span class="nav-number">8.2.</span> <span class="nav-text">AOF</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#工作流程"><span class="nav-number">8.2.1.</span> <span class="nav-text">工作流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-4-0-对于持久化机制的优化"><span class="nav-number">8.2.2.</span> <span class="nav-text">Redis 4.0 对于持久化机制的优化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#AOF重写机制"><span class="nav-number">8.2.3.</span> <span class="nav-text">AOF重写机制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#重写过程的触发："><span class="nav-number">8.2.3.1.</span> <span class="nav-text">重写过程的触发：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#重写流程"><span class="nav-number">8.2.3.2.</span> <span class="nav-text">重写流程</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#9-Redis事务"><span class="nav-number">9.</span> <span class="nav-text">9. Redis事务</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#10-缓存雪崩问题解决方案"><span class="nav-number">10.</span> <span class="nav-text">10. 缓存雪崩问题解决方案</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#11-缓存穿透问题解决方案"><span class="nav-number">11.</span> <span class="nav-text">11. 缓存穿透问题解决方案</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#12-如何解决Redis的并发竞争key问题"><span class="nav-number">12.</span> <span class="nav-text">12. 如何解决Redis的并发竞争key问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#13-如何保证缓存与数据库双写时的数据一致性？"><span class="nav-number">13.</span> <span class="nav-text">13. 如何保证缓存与数据库双写时的数据一致性？</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#为什么是删除缓存而不是更新缓存？"><span class="nav-number">13.1.</span> <span class="nav-text">为什么是删除缓存而不是更新缓存？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cache-Aside-Pattern存在的问题"><span class="nav-number">13.2.</span> <span class="nav-text">Cache Aside Pattern存在的问题</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#14-Redlock分布式锁"><span class="nav-number">14.</span> <span class="nav-text">14. Redlock分布式锁</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#怎么在单点上实现分布式锁"><span class="nav-number">14.1.</span> <span class="nav-text">怎么在单点上实现分布式锁</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Redlock算法"><span class="nav-number">14.2.</span> <span class="nav-text">Redlock算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#失败重试"><span class="nav-number">14.3.</span> <span class="nav-text">失败重试</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#放锁"><span class="nav-number">14.4.</span> <span class="nav-text">放锁</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#性能、崩溃恢复和fsync"><span class="nav-number">14.5.</span> <span class="nav-text">性能、崩溃恢复和fsync</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RedLock缺陷"><span class="nav-number">14.6.</span> <span class="nav-text">RedLock缺陷</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RedLock算法不可靠的场景"><span class="nav-number">14.6.1.</span> <span class="nav-text">RedLock算法不可靠的场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#解决方式"><span class="nav-number">14.6.2.</span> <span class="nav-text">解决方式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#使用Fencing（栏栅）使锁变安全"><span class="nav-number">14.6.2.1.</span> <span class="nav-text">使用Fencing（栏栅）使锁变安全</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用时间来解决一致性"><span class="nav-number">14.6.2.2.</span> <span class="nav-text">使用时间来解决一致性</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Redlock不可靠的例子"><span class="nav-number">14.6.2.3.</span> <span class="nav-text">Redlock不可靠的例子</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#15-Redis底层实现-用到了哪些数据结构"><span class="nav-number">15.</span> <span class="nav-text">15. Redis底层实现/用到了哪些数据结构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#字典（也叫哈希）"><span class="nav-number">15.1.</span> <span class="nav-text">字典（也叫哈希）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#跳跃表"><span class="nav-number">15.2.</span> <span class="nav-text">跳跃表</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#16-主从复制"><span class="nav-number">16.</span> <span class="nav-text">16. 主从复制</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#主从复制下数据同步方法"><span class="nav-number">16.1.</span> <span class="nav-text">主从复制下数据同步方法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#17-Redis-哨兵模式"><span class="nav-number">17.</span> <span class="nav-text">17. Redis 哨兵模式</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#部署方式"><span class="nav-number">17.1.</span> <span class="nav-text">部署方式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实现原理"><span class="nav-number">17.2.</span> <span class="nav-text">实现原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#三个定时任务"><span class="nav-number">17.2.1.</span> <span class="nav-text">三个定时任务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#主观下线和客观下线"><span class="nav-number">17.2.2.</span> <span class="nav-text">主观下线和客观下线</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#主节点选取"><span class="nav-number">17.2.3.</span> <span class="nav-text">主节点选取</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#18-Sorted-Set（即-ZSet-实现原理）"><span class="nav-number">18.</span> <span class="nav-text">18. Sorted Set（即 ZSet 实现原理）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ZipList"><span class="nav-number">18.1.</span> <span class="nav-text">ZipList</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Skiplist"><span class="nav-number">18.2.</span> <span class="nav-text">Skiplist</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#跳表数据结构"><span class="nav-number">18.2.1.</span> <span class="nav-text">跳表数据结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Skiplist-与平衡树、哈希表的比较"><span class="nav-number">18.2.2.</span> <span class="nav-text">Skiplist 与平衡树、哈希表的比较</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-中-Skiplist-的实现"><span class="nav-number">18.2.3.</span> <span class="nav-text">Redis 中 Skiplist 的实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Redis-Zset-采用跳表而不是平衡树的原因"><span class="nav-number">18.2.4.</span> <span class="nav-text">Redis Zset 采用跳表而不是平衡树的原因</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#19-Redis-为什么那么快？"><span class="nav-number">19.</span> <span class="nav-text">19. Redis 为什么那么快？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#20-Redis-集群原理"><span class="nav-number">20.</span> <span class="nav-text">20. Redis 集群原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#集群数据分区"><span class="nav-number">20.1.</span> <span class="nav-text">集群数据分区</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#节点通信"><span class="nav-number">20.2.</span> <span class="nav-text">节点通信</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Gossip消息"><span class="nav-number">20.2.1.</span> <span class="nav-text">Gossip消息</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#优势"><span class="nav-number">20.2.1.1.</span> <span class="nav-text">优势</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Gossip-的缺陷"><span class="nav-number">20.2.1.2.</span> <span class="nav-text">Gossip 的缺陷</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#节点选择"><span class="nav-number">20.3.</span> <span class="nav-text">节点选择</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#选择发送消息的节点数量"><span class="nav-number">20.3.1.</span> <span class="nav-text">选择发送消息的节点数量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#消息数据量"><span class="nav-number">20.3.2.</span> <span class="nav-text">消息数据量</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#21-Redis-集群如何进行故障迁移"><span class="nav-number">21.</span> <span class="nav-text">21. Redis 集群如何进行故障迁移</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#故障发现"><span class="nav-number">21.1.</span> <span class="nav-text">故障发现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#主观下线"><span class="nav-number">21.1.1.</span> <span class="nav-text">主观下线</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#客观下线"><span class="nav-number">21.1.2.</span> <span class="nav-text">客观下线</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#下线报告链表"><span class="nav-number">21.1.2.1.</span> <span class="nav-text">下线报告链表</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#尝试客观下线"><span class="nav-number">21.1.2.2.</span> <span class="nav-text">尝试客观下线</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#故障恢复"><span class="nav-number">21.2.</span> <span class="nav-text">故障恢复</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#资格检查"><span class="nav-number">21.2.1.</span> <span class="nav-text">资格检查</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#准备选举时间"><span class="nav-number">21.2.2.</span> <span class="nav-text">准备选举时间</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#发起选举"><span class="nav-number">21.2.3.</span> <span class="nav-text">发起选举</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#更新配置纪元："><span class="nav-number">21.2.4.</span> <span class="nav-text">更新配置纪元：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#广播选举消息"><span class="nav-number">21.2.5.</span> <span class="nav-text">广播选举消息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#选举投票"><span class="nav-number">21.2.6.</span> <span class="nav-text">选举投票</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#替换主节点"><span class="nav-number">21.2.7.</span> <span class="nav-text">替换主节点</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#22-Redis-集群伸缩（增加节点、删除节点）"><span class="nav-number">22.</span> <span class="nav-text">22. Redis 集群伸缩（增加节点、删除节点）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#集群扩容"><span class="nav-number">22.1.</span> <span class="nav-text">集群扩容</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#设置节点迁入迁出状态——解决路由困境"><span class="nav-number">22.1.1.</span> <span class="nav-text">设置节点迁入迁出状态——解决路由困境</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#集群收缩"><span class="nav-number">22.2.</span> <span class="nav-text">集群收缩</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#23-Redis应用场景"><span class="nav-number">23.</span> <span class="nav-text">23. Redis应用场景</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#热点数据"><span class="nav-number">23.1.</span> <span class="nav-text">热点数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#会话维持-Session"><span class="nav-number">23.2.</span> <span class="nav-text">会话维持 Session</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分布式锁-SETNX"><span class="nav-number">23.3.</span> <span class="nav-text">分布式锁 SETNX</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#表缓存"><span class="nav-number">23.4.</span> <span class="nav-text">表缓存</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#消息队列-list"><span class="nav-number">23.5.</span> <span class="nav-text">消息队列 list</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#计数器-string"><span class="nav-number">23.6.</span> <span class="nav-text">计数器 string</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#24-Redis-压力测试"><span class="nav-number">24.</span> <span class="nav-text">24. Redis 压力测试</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Silverming</p>
  <div class="site-description" itemprop="description">Wechat:934933088</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">114</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">33</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Silverming</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.5.0
  </div>
  <div>
     <a href="http://www.beianbeian.com/beianxinxi/56c155c0ed5f44020af3c1659377b89d.html" target="_blank" rel="noopener">粤ICP备18114217号</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/muse.js"></script>
<script src="/js/next-boot.js"></script>



  




  <script src="/js/local-search.js"></script>













  

  

</body>
</html>
